{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f30e184-799d-40cc-a305-8d9322773c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qas.mcts import search, TreeNode, circuitModelTuning\n",
    "from qas.qml_gate_ops import QMLPool\n",
    "from qas.qml_models import ToffoliQMLNoiselessAdditionalData, ToffoliQMLSwapTestNoiselessExtendedData, ToffoliQMLNoiseless, ToffoliQMLNoiselessFullInput\n",
    "import json\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import time\n",
    "from qas.mcts import QMLStateBasicGates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7afc4f15-90ea-4d1c-9f03-1db58dc95c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"0\": {\"U3\": [0]}, \"1\": {\"PlaceHolder\": [0]}, \"2\": {\"U3\": [1]}, \"3\": {\"PlaceHolder\": [1]}, \"4\": {\"U3\": [2]}, \"5\": {\"PlaceHolder\": [2]}, \"6\": {\"CNOT\": [0, 1]}, \"7\": {\"CNOT\": [1, 2]}, \"8\": {\"CNOT\": [0, 2]}}\n"
     ]
    }
   ],
   "source": [
    "model = ToffoliQMLNoiselessFullInput\n",
    "state_class = QMLStateBasicGates\n",
    "init_qubit_with_actions = {0, 1, 2}\n",
    "two_qubit_gate = [\"CNOT\"]\n",
    "single_qubit_gate = ['U3','PlaceHolder']\n",
    "gate_limit = {\"CNOT\": 6}\n",
    "control_map = [[0, 1], [1, 2], [0, 2]]\n",
    "pool = QMLPool(3, single_qubit_gate, two_qubit_gate, complete_undirected_graph=False,two_qubit_gate_map=control_map)\n",
    "print(pool)\n",
    "p = 16\n",
    "l = 3\n",
    "c = len(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ee95157-d776-4036-a316-4191c4e1fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "intended_k = [4,7,4,8,4,7,4,8,4,4,2,6,2,6,0,2]\n",
    "init_params = np.random.randn(p, c, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7544e8a-2855-4e0e-8a35-0d3e2cab88db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Circuit at Epoch 1/500; Loss: 0.8725950806253323\n",
      "Training Circuit at Epoch 2/500; Loss: 0.8660654029216173\n",
      "Training Circuit at Epoch 3/500; Loss: 0.8608641136095332\n",
      "Training Circuit at Epoch 4/500; Loss: 0.8561326061884665\n",
      "Training Circuit at Epoch 5/500; Loss: 0.8515806374618359\n",
      "Training Circuit at Epoch 6/500; Loss: 0.8470630829800505\n",
      "Training Circuit at Epoch 7/500; Loss: 0.842492323867028\n",
      "Training Circuit at Epoch 8/500; Loss: 0.8378083411608559\n",
      "Training Circuit at Epoch 9/500; Loss: 0.8329659202458424\n",
      "Training Circuit at Epoch 10/500; Loss: 0.8279286025177773\n",
      "Training Circuit at Epoch 11/500; Loss: 0.8226656010430221\n",
      "Training Circuit at Epoch 12/500; Loss: 0.8171501175686471\n",
      "Training Circuit at Epoch 13/500; Loss: 0.8113583801974003\n",
      "Training Circuit at Epoch 14/500; Loss: 0.8052690828485203\n",
      "Training Circuit at Epoch 15/500; Loss: 0.798863061457487\n",
      "Training Circuit at Epoch 16/500; Loss: 0.7921231114522127\n",
      "Training Circuit at Epoch 17/500; Loss: 0.785033885098011\n",
      "Training Circuit at Epoch 18/500; Loss: 0.7775818253796126\n",
      "Training Circuit at Epoch 19/500; Loss: 0.7697551036992352\n",
      "Training Circuit at Epoch 20/500; Loss: 0.7615435361594285\n",
      "Training Circuit at Epoch 21/500; Loss: 0.7529384602397469\n",
      "Training Circuit at Epoch 22/500; Loss: 0.7439325621557651\n",
      "Training Circuit at Epoch 23/500; Loss: 0.7345196564737209\n",
      "Training Circuit at Epoch 24/500; Loss: 0.724694434407231\n",
      "Training Circuit at Epoch 25/500; Loss: 0.7144522154763651\n",
      "Training Circuit at Epoch 26/500; Loss: 0.7037887573036896\n",
      "Training Circuit at Epoch 27/500; Loss: 0.6927001968499793\n",
      "Training Circuit at Epoch 28/500; Loss: 0.6811832076286013\n",
      "Training Circuit at Epoch 29/500; Loss: 0.6692354527418967\n",
      "Training Circuit at Epoch 30/500; Loss: 0.6568563819748081\n",
      "Training Circuit at Epoch 31/500; Loss: 0.644048355549732\n",
      "Training Circuit at Epoch 32/500; Loss: 0.6308179882552235\n",
      "Training Circuit at Epoch 33/500; Loss: 0.6171775319014371\n",
      "Training Circuit at Epoch 34/500; Loss: 0.6031460921965762\n",
      "Training Circuit at Epoch 35/500; Loss: 0.5887505152803619\n",
      "Training Circuit at Epoch 36/500; Loss: 0.5740258465426916\n",
      "Training Circuit at Epoch 37/500; Loss: 0.5590153224552095\n",
      "Training Circuit at Epoch 38/500; Loss: 0.5437698919146319\n",
      "Training Circuit at Epoch 39/500; Loss: 0.5283472861108927\n",
      "Training Circuit at Epoch 40/500; Loss: 0.5128106813285338\n",
      "Training Circuit at Epoch 41/500; Loss: 0.4972270392535617\n",
      "Training Circuit at Epoch 42/500; Loss: 0.4816652590639997\n",
      "Training Circuit at Epoch 43/500; Loss: 0.4661942974560491\n",
      "Training Circuit at Epoch 44/500; Loss: 0.45088135193799195\n",
      "Training Circuit at Epoch 45/500; Loss: 0.4357900627435731\n",
      "Training Circuit at Epoch 46/500; Loss: 0.4209785868804492\n",
      "Training Circuit at Epoch 47/500; Loss: 0.40649745516151625\n",
      "Training Circuit at Epoch 48/500; Loss: 0.39238730162888347\n",
      "Training Circuit at Epoch 49/500; Loss: 0.37867671421890836\n",
      "Training Circuit at Epoch 50/500; Loss: 0.36538053242470925\n",
      "Training Circuit at Epoch 51/500; Loss: 0.35249894974458607\n",
      "Training Circuit at Epoch 52/500; Loss: 0.3400177980752168\n",
      "Training Circuit at Epoch 53/500; Loss: 0.32791034515903716\n",
      "Training Circuit at Epoch 54/500; Loss: 0.31614069948736756\n",
      "Training Circuit at Epoch 55/500; Loss: 0.3046684438479349\n",
      "Training Circuit at Epoch 56/500; Loss: 0.293453640240518\n",
      "Training Circuit at Epoch 57/500; Loss: 0.2824612372170491\n",
      "Training Circuit at Epoch 58/500; Loss: 0.2716642263620096\n",
      "Training Circuit at Epoch 59/500; Loss: 0.2610453365914869\n",
      "Training Circuit at Epoch 60/500; Loss: 0.2505973702511207\n",
      "Training Circuit at Epoch 61/500; Loss: 0.24032244024835314\n",
      "Training Circuit at Epoch 62/500; Loss: 0.23023041319429438\n",
      "Training Circuit at Epoch 63/500; Loss: 0.22033684214913551\n",
      "Training Circuit at Epoch 64/500; Loss: 0.21066062215331072\n",
      "Training Circuit at Epoch 65/500; Loss: 0.20122156191208174\n",
      "Training Circuit at Epoch 66/500; Loss: 0.19203806161935155\n",
      "Training Circuit at Epoch 67/500; Loss: 0.18312511552654975\n",
      "Training Circuit at Epoch 68/500; Loss: 0.17449288344471137\n",
      "Training Circuit at Epoch 69/500; Loss: 0.16614605183477094\n",
      "Training Circuit at Epoch 70/500; Loss: 0.1580841047199304\n",
      "Training Circuit at Epoch 71/500; Loss: 0.15030245850276813\n",
      "Training Circuit at Epoch 72/500; Loss: 0.1427942301906674\n",
      "Training Circuit at Epoch 73/500; Loss: 0.1355522656490682\n",
      "Training Circuit at Epoch 74/500; Loss: 0.12857100040700697\n",
      "Training Circuit at Epoch 75/500; Loss: 0.12184777812570058\n",
      "Training Circuit at Epoch 76/500; Loss: 0.11538339371540807\n",
      "Training Circuit at Epoch 77/500; Loss: 0.10918181257958548\n",
      "Training Circuit at Epoch 78/500; Loss: 0.10324918873539868\n",
      "Training Circuit at Epoch 79/500; Loss: 0.09759242176285188\n",
      "Training Circuit at Epoch 80/500; Loss: 0.09221754229705259\n",
      "Training Circuit at Epoch 81/500; Loss: 0.08712820759462492\n",
      "Training Circuit at Epoch 82/500; Loss: 0.08232454115587262\n",
      "Training Circuit at Epoch 83/500; Loss: 0.07780247935151785\n",
      "Training Circuit at Epoch 84/500; Loss: 0.07355370278610729\n",
      "Training Circuit at Epoch 85/500; Loss: 0.06956613676312273\n",
      "Training Circuit at Epoch 86/500; Loss: 0.0658249124993272\n",
      "Training Circuit at Epoch 87/500; Loss: 0.06231360369674199\n",
      "Training Circuit at Epoch 88/500; Loss: 0.05901551035049135\n",
      "Training Circuit at Epoch 89/500; Loss: 0.05591476730481704\n",
      "Training Circuit at Epoch 90/500; Loss: 0.05299710985405337\n",
      "Training Circuit at Epoch 91/500; Loss: 0.05025021730543611\n",
      "Training Circuit at Epoch 92/500; Loss: 0.047663652108556165\n",
      "Training Circuit at Epoch 93/500; Loss: 0.045228491350110644\n",
      "Training Circuit at Epoch 94/500; Loss: 0.0429367928449379\n",
      "Training Circuit at Epoch 95/500; Loss: 0.04078104585127229\n",
      "Training Circuit at Epoch 96/500; Loss: 0.038753732525832474\n",
      "Training Circuit at Epoch 97/500; Loss: 0.036847081460895326\n",
      "Training Circuit at Epoch 98/500; Loss: 0.035053040836601546\n",
      "Training Circuit at Epoch 99/500; Loss: 0.03336344677951897\n",
      "Training Circuit at Epoch 100/500; Loss: 0.031770321753862296\n",
      "Training Circuit at Epoch 101/500; Loss: 0.030266215217567893\n",
      "Training Circuit at Epoch 102/500; Loss: 0.028844497747307685\n",
      "Training Circuit at Epoch 103/500; Loss: 0.027499538999148143\n",
      "Training Circuit at Epoch 104/500; Loss: 0.02622673311273893\n",
      "Training Circuit at Epoch 105/500; Loss: 0.025022373354156024\n",
      "Training Circuit at Epoch 106/500; Loss: 0.023883411526011922\n",
      "Training Circuit at Epoch 107/500; Loss: 0.022807159815192324\n",
      "Training Circuit at Epoch 108/500; Loss: 0.021790999793072863\n",
      "Training Circuit at Epoch 109/500; Loss: 0.020832155462112478\n",
      "Training Circuit at Epoch 110/500; Loss: 0.01992756783471361\n",
      "Training Circuit at Epoch 111/500; Loss: 0.019073882853170132\n",
      "Training Circuit at Epoch 112/500; Loss: 0.018267538735343924\n",
      "Training Circuit at Epoch 113/500; Loss: 0.017504918905141942\n",
      "Training Circuit at Epoch 114/500; Loss: 0.01678252668731517\n",
      "Training Circuit at Epoch 115/500; Loss: 0.016097139327739707\n",
      "Training Circuit at Epoch 116/500; Loss: 0.015445910029853516\n",
      "Training Circuit at Epoch 117/500; Loss: 0.01482640358262266\n",
      "Training Circuit at Epoch 118/500; Loss: 0.014236568809227412\n",
      "Training Circuit at Epoch 119/500; Loss: 0.013674665053434065\n",
      "Training Circuit at Epoch 120/500; Loss: 0.013139167471954982\n",
      "Training Circuit at Epoch 121/500; Loss: 0.012628676298026553\n",
      "Training Circuit at Epoch 122/500; Loss: 0.01214184956525366\n",
      "Training Circuit at Epoch 123/500; Loss: 0.011677369314951336\n",
      "Training Circuit at Epoch 124/500; Loss: 0.011233940859206037\n",
      "Training Circuit at Epoch 125/500; Loss: 0.010810315922269886\n",
      "Training Circuit at Epoch 126/500; Loss: 0.010405325440493551\n",
      "Training Circuit at Epoch 127/500; Loss: 0.010017907365133638\n",
      "Training Circuit at Epoch 128/500; Loss: 0.009647118592518544\n",
      "Training Circuit at Epoch 129/500; Loss: 0.00929212662137513\n",
      "Training Circuit at Epoch 130/500; Loss: 0.00895218354676075\n",
      "Training Circuit at Epoch 131/500; Loss: 0.008626590425205083\n",
      "Training Circuit at Epoch 132/500; Loss: 0.008314662448557275\n",
      "Training Circuit at Epoch 133/500; Loss: 0.008015704367925536\n",
      "Training Circuit at Epoch 134/500; Loss: 0.0077290019022718814\n",
      "Training Circuit at Epoch 135/500; Loss: 0.007453829865328276\n",
      "Training Circuit at Epoch 136/500; Loss: 0.007189473067401586\n",
      "Training Circuit at Epoch 137/500; Loss: 0.006935252999339503\n",
      "Training Circuit at Epoch 138/500; Loss: 0.006690552535420391\n",
      "Training Circuit at Epoch 139/500; Loss: 0.006454832313544934\n",
      "Training Circuit at Epoch 140/500; Loss: 0.006227635384293162\n",
      "Training Circuit at Epoch 141/500; Loss: 0.006008580172677136\n",
      "Training Circuit at Epoch 142/500; Loss: 0.005797344775095525\n",
      "Training Circuit at Epoch 143/500; Loss: 0.005593647381832656\n",
      "Training Circuit at Epoch 144/500; Loss: 0.005397227847658392\n",
      "Training Circuit at Epoch 145/500; Loss: 0.005207834258677102\n",
      "Training Circuit at Epoch 146/500; Loss: 0.005025216272226296\n",
      "Training Circuit at Epoch 147/500; Loss: 0.004849124758318224\n",
      "Training Circuit at Epoch 148/500; Loss: 0.004679315546040841\n",
      "Training Circuit at Epoch 149/500; Loss: 0.004515554337877314\n",
      "Training Circuit at Epoch 150/500; Loss: 0.0043576201885104915\n",
      "Training Circuit at Epoch 151/500; Loss: 0.004205306075067083\n",
      "Training Circuit at Epoch 152/500; Loss: 0.00405841650574934\n",
      "Training Circuit at Epoch 153/500; Loss: 0.003916763294280368\n",
      "Training Circuit at Epoch 154/500; Loss: 0.0037801612057631884\n",
      "Training Circuit at Epoch 155/500; Loss: 0.003648425057022342\n",
      "Training Circuit at Epoch 156/500; Loss: 0.0035213691850923823\n",
      "Training Circuit at Epoch 157/500; Loss: 0.0033988092896320987\n",
      "Training Circuit at Epoch 158/500; Loss: 0.003280565844788641\n",
      "Training Circuit at Epoch 159/500; Loss: 0.0031664678175626904\n",
      "Training Circuit at Epoch 160/500; Loss: 0.0030563554324747333\n",
      "Training Circuit at Epoch 161/500; Loss: 0.0029500811369247426\n",
      "Training Circuit at Epoch 162/500; Loss: 0.002847508573471491\n",
      "Training Circuit at Epoch 163/500; Loss: 0.00274851001799703\n",
      "Training Circuit at Epoch 164/500; Loss: 0.0026529631791322172\n",
      "Training Circuit at Epoch 165/500; Loss: 0.0025607483487116722\n",
      "Training Circuit at Epoch 166/500; Loss: 0.0024717466496444462\n",
      "Training Circuit at Epoch 167/500; Loss: 0.002385839670268619\n",
      "Training Circuit at Epoch 168/500; Loss: 0.002302910289707083\n",
      "Training Circuit at Epoch 169/500; Loss: 0.0022228441588068026\n",
      "Training Circuit at Epoch 170/500; Loss: 0.002145531200600681\n",
      "Training Circuit at Epoch 171/500; Loss: 0.0020708666256468167\n",
      "Training Circuit at Epoch 172/500; Loss: 0.001998751232749507\n",
      "Training Circuit at Epoch 173/500; Loss: 0.0019290910621760915\n",
      "Training Circuit at Epoch 174/500; Loss: 0.0018617966801938168\n",
      "Training Circuit at Epoch 175/500; Loss: 0.001796782443324263\n",
      "Training Circuit at Epoch 176/500; Loss: 0.001733966019475841\n",
      "Training Circuit at Epoch 177/500; Loss: 0.0016732682801945398\n",
      "Training Circuit at Epoch 178/500; Loss: 0.0016146134974415194\n",
      "Training Circuit at Epoch 179/500; Loss: 0.0015579296504868445\n",
      "Training Circuit at Epoch 180/500; Loss: 0.0015031486169753139\n",
      "Training Circuit at Epoch 181/500; Loss: 0.0014502060888490487\n",
      "Training Circuit at Epoch 182/500; Loss: 0.0013990411806793501\n",
      "Training Circuit at Epoch 183/500; Loss: 0.0013495958268583408\n",
      "Training Circuit at Epoch 184/500; Loss: 0.0013018141414306017\n",
      "Training Circuit at Epoch 185/500; Loss: 0.0012556419150393516\n",
      "Training Circuit at Epoch 186/500; Loss: 0.0012110263566600388\n",
      "Training Circuit at Epoch 187/500; Loss: 0.001167916089116594\n",
      "Training Circuit at Epoch 188/500; Loss: 0.0011262613193069315\n",
      "Training Circuit at Epoch 189/500; Loss: 0.0010860140579305178\n",
      "Training Circuit at Epoch 190/500; Loss: 0.0010471282697898099\n",
      "Training Circuit at Epoch 191/500; Loss: 0.0010095598837519537\n",
      "Training Circuit at Epoch 192/500; Loss: 0.0009732666576340865\n",
      "Training Circuit at Epoch 193/500; Loss: 0.000938207950210268\n",
      "Training Circuit at Epoch 194/500; Loss: 0.0009043444805241219\n",
      "Training Circuit at Epoch 195/500; Loss: 0.0008716381465219136\n",
      "Training Circuit at Epoch 196/500; Loss: 0.0008400519391938976\n",
      "Training Circuit at Epoch 197/500; Loss: 0.0008095499434255249\n",
      "Training Circuit at Epoch 198/500; Loss: 0.0007800973832096103\n",
      "Training Circuit at Epoch 199/500; Loss: 0.0007516606593497288\n",
      "Training Circuit at Epoch 200/500; Loss: 0.0007242073426422246\n",
      "Training Circuit at Epoch 201/500; Loss: 0.0006977061141122398\n",
      "Training Circuit at Epoch 202/500; Loss: 0.0006721266709733831\n",
      "Training Circuit at Epoch 203/500; Loss: 0.0006474396311116903\n",
      "Training Circuit at Epoch 204/500; Loss: 0.0006236164659704224\n",
      "Training Circuit at Epoch 205/500; Loss: 0.0006006294756694119\n",
      "Training Circuit at Epoch 206/500; Loss: 0.0005784518000572225\n",
      "Training Circuit at Epoch 207/500; Loss: 0.0005570574442504972\n",
      "Training Circuit at Epoch 208/500; Loss: 0.0005364212929622747\n",
      "Training Circuit at Epoch 209/500; Loss: 0.000516519095635104\n",
      "Training Circuit at Epoch 210/500; Loss: 0.0004973274191345523\n",
      "Training Circuit at Epoch 211/500; Loss: 0.00047882357958861643\n",
      "Training Circuit at Epoch 212/500; Loss: 0.0004609855728590073\n",
      "Training Circuit at Epoch 213/500; Loss: 0.00044379202140332197\n",
      "Training Circuit at Epoch 214/500; Loss: 0.00042722214597112895\n",
      "Training Circuit at Epoch 215/500; Loss: 0.00041125575893985467\n",
      "Training Circuit at Epoch 216/500; Loss: 0.00039587326805090584\n",
      "Training Circuit at Epoch 217/500; Loss: 0.0003810556775842855\n",
      "Training Circuit at Epoch 218/500; Loss: 0.0003667845784969259\n",
      "Training Circuit at Epoch 219/500; Loss: 0.0003530421262697425\n",
      "Training Circuit at Epoch 220/500; Loss: 0.0003398110116884512\n",
      "Training Circuit at Epoch 221/500; Loss: 0.00032707443247514956\n",
      "Training Circuit at Epoch 222/500; Loss: 0.000314816072206181\n",
      "Training Circuit at Epoch 223/500; Loss: 0.0003030200883641365\n",
      "Training Circuit at Epoch 224/500; Loss: 0.00029167110657968287\n",
      "Training Circuit at Epoch 225/500; Loss: 0.0002807542154811271\n",
      "Training Circuit at Epoch 226/500; Loss: 0.0002702549571295121\n",
      "Training Circuit at Epoch 227/500; Loss: 0.00026015931124734326\n",
      "Training Circuit at Epoch 228/500; Loss: 0.00025045367514764383\n",
      "Training Circuit at Epoch 229/500; Loss: 0.00024112484352700747\n",
      "Training Circuit at Epoch 230/500; Loss: 0.00023215999208181515\n",
      "Training Circuit at Epoch 231/500; Loss: 0.00022354666670731937\n",
      "Training Circuit at Epoch 232/500; Loss: 0.0002152727773356844\n",
      "Training Circuit at Epoch 233/500; Loss: 0.0002073265935250701\n",
      "Training Circuit at Epoch 234/500; Loss: 0.00019969673870112725\n",
      "Training Circuit at Epoch 235/500; Loss: 0.00019237218122825084\n",
      "Training Circuit at Epoch 236/500; Loss: 0.00018534222238630882\n",
      "Training Circuit at Epoch 237/500; Loss: 0.0001785964830324227\n",
      "Training Circuit at Epoch 238/500; Loss: 0.0001721248911118467\n",
      "Training Circuit at Epoch 239/500; Loss: 0.00016591767156004522\n",
      "Training Circuit at Epoch 240/500; Loss: 0.0001599653386958888\n",
      "Training Circuit at Epoch 241/500; Loss: 0.00015425869009155768\n",
      "Training Circuit at Epoch 242/500; Loss: 0.00014878880048119214\n",
      "Training Circuit at Epoch 243/500; Loss: 0.00014354701478391796\n",
      "Training Circuit at Epoch 244/500; Loss: 0.0001385249402026112\n",
      "Training Circuit at Epoch 245/500; Loss: 0.00013371443811172057\n",
      "Training Circuit at Epoch 246/500; Loss: 0.00012910761664719494\n",
      "Training Circuit at Epoch 247/500; Loss: 0.00012469682457882936\n",
      "Training Circuit at Epoch 248/500; Loss: 0.00012047464634989957\n",
      "Training Circuit at Epoch 249/500; Loss: 0.00011643389766879952\n",
      "Training Circuit at Epoch 250/500; Loss: 0.00011256762084277394\n",
      "Training Circuit at Epoch 251/500; Loss: 0.00010886907933438383\n",
      "Training Circuit at Epoch 252/500; Loss: 0.00010533175158899954\n",
      "Training Circuit at Epoch 253/500; Loss: 0.00010194932454987704\n",
      "Training Circuit at Epoch 254/500; Loss: 9.871568751940174e-05\n",
      "Training Circuit at Epoch 255/500; Loss: 9.562492667591904e-05\n",
      "Training Circuit at Epoch 256/500; Loss: 9.267132028489833e-05\n",
      "Training Circuit at Epoch 257/500; Loss: 8.984933427480524e-05\n",
      "Training Circuit at Epoch 258/500; Loss: 8.715361778888209e-05\n",
      "Training Circuit at Epoch 259/500; Loss: 8.457899850655703e-05\n",
      "Training Circuit at Epoch 260/500; Loss: 8.212047776923193e-05\n",
      "Training Circuit at Epoch 261/500; Loss: 7.977322569330259e-05\n",
      "Training Circuit at Epoch 262/500; Loss: 7.753257655662704e-05\n",
      "Training Circuit at Epoch 263/500; Loss: 7.539402453327071e-05\n",
      "Training Circuit at Epoch 264/500; Loss: 7.335321972279374e-05\n",
      "Training Circuit at Epoch 265/500; Loss: 7.14059642697995e-05\n",
      "Training Circuit at Epoch 266/500; Loss: 6.954820837434816e-05\n",
      "Training Circuit at Epoch 267/500; Loss: 6.77760461773591e-05\n",
      "Training Circuit at Epoch 268/500; Loss: 6.608571158595034e-05\n",
      "Training Circuit at Epoch 269/500; Loss: 6.447357421146549e-05\n",
      "Training Circuit at Epoch 270/500; Loss: 6.29361355530822e-05\n",
      "Training Circuit at Epoch 271/500; Loss: 6.147002541312396e-05\n",
      "Training Circuit at Epoch 272/500; Loss: 6.0071998492117196e-05\n",
      "Training Circuit at Epoch 273/500; Loss: 5.87389310267028e-05\n",
      "Training Circuit at Epoch 274/500; Loss: 5.746781738824591e-05\n",
      "Training Circuit at Epoch 275/500; Loss: 5.6255766653801054e-05\n",
      "Training Circuit at Epoch 276/500; Loss: 5.5099999196173144e-05\n",
      "Training Circuit at Epoch 277/500; Loss: 5.399784339188418e-05\n",
      "Training Circuit at Epoch 278/500; Loss: 5.294673243205761e-05\n",
      "Training Circuit at Epoch 279/500; Loss: 5.194420127607735e-05\n",
      "Training Circuit at Epoch 280/500; Loss: 5.098788362778439e-05\n",
      "Training Circuit at Epoch 281/500; Loss: 5.007550892965895e-05\n",
      "Training Circuit at Epoch 282/500; Loss: 4.920489935256178e-05\n",
      "Training Circuit at Epoch 283/500; Loss: 4.837396683010642e-05\n",
      "Training Circuit at Epoch 284/500; Loss: 4.7580710184735864e-05\n",
      "Training Circuit at Epoch 285/500; Loss: 4.68232123396195e-05\n",
      "Training Circuit at Epoch 286/500; Loss: 4.609963765822567e-05\n",
      "Training Circuit at Epoch 287/500; Loss: 4.540822932497246e-05\n",
      "Training Circuit at Epoch 288/500; Loss: 4.47473067738402e-05\n",
      "Training Circuit at Epoch 289/500; Loss: 4.4115263138744254e-05\n",
      "Training Circuit at Epoch 290/500; Loss: 4.351056272877685e-05\n",
      "Training Circuit at Epoch 291/500; Loss: 4.2931738570617384e-05\n",
      "Training Circuit at Epoch 292/500; Loss: 4.237739002577179e-05\n",
      "Training Circuit at Epoch 293/500; Loss: 4.184618047109456e-05\n",
      "Training Circuit at Epoch 294/500; Loss: 4.133683503793062e-05\n",
      "Training Circuit at Epoch 295/500; Loss: 4.0848138401439194e-05\n",
      "Training Circuit at Epoch 296/500; Loss: 4.037893259645209e-05\n",
      "Training Circuit at Epoch 297/500; Loss: 3.992811487585346e-05\n",
      "Training Circuit at Epoch 298/500; Loss: 3.949463565333655e-05\n",
      "Training Circuit at Epoch 299/500; Loss: 3.9077496476691564e-05\n",
      "Training Circuit at Epoch 300/500; Loss: 3.867574809635066e-05\n",
      "Training Circuit at Epoch 301/500; Loss: 3.82884885570256e-05\n",
      "Training Circuit at Epoch 302/500; Loss: 3.791486135518163e-05\n",
      "Training Circuit at Epoch 303/500; Loss: 3.755405362160236e-05\n",
      "Training Circuit at Epoch 304/500; Loss: 3.720529435480291e-05\n",
      "Training Circuit at Epoch 305/500; Loss: 3.686785269918502e-05\n",
      "Training Circuit at Epoch 306/500; Loss: 3.654103629024963e-05\n",
      "Training Circuit at Epoch 307/500; Loss: 3.622418963822316e-05\n",
      "Training Circuit at Epoch 308/500; Loss: 3.59166925697485e-05\n",
      "Training Circuit at Epoch 309/500; Loss: 3.5617958708100694e-05\n",
      "Training Circuit at Epoch 310/500; Loss: 3.5327433996923396e-05\n",
      "Training Circuit at Epoch 311/500; Loss: 3.5044595275257606e-05\n",
      "Training Circuit at Epoch 312/500; Loss: 3.476894889520299e-05\n",
      "Training Circuit at Epoch 313/500; Loss: 3.450002938121255e-05\n",
      "Training Circuit at Epoch 314/500; Loss: 3.423739815267002e-05\n",
      "Training Circuit at Epoch 315/500; Loss: 3.3980642274111794e-05\n",
      "Training Circuit at Epoch 316/500; Loss: 3.372937324352954e-05\n",
      "Training Circuit at Epoch 317/500; Loss: 3.348322582874541e-05\n",
      "Training Circuit at Epoch 318/500; Loss: 3.3241856941312875e-05\n",
      "Training Circuit at Epoch 319/500; Loss: 3.300494454516745e-05\n",
      "Training Circuit at Epoch 320/500; Loss: 3.27721866206776e-05\n",
      "Training Circuit at Epoch 321/500; Loss: 3.254330015545204e-05\n",
      "Training Circuit at Epoch 322/500; Loss: 3.2318020176780315e-05\n",
      "Training Circuit at Epoch 323/500; Loss: 3.20960988279273e-05\n",
      "Training Circuit at Epoch 324/500; Loss: 3.1877304458638456e-05\n",
      "Training Circuit at Epoch 325/500; Loss: 3.1661420774264926e-05\n",
      "Training Circuit at Epoch 326/500; Loss: 3.144824601419849e-05\n",
      "Training Circuit at Epoch 327/500; Loss: 3.123759215672983e-05\n",
      "Training Circuit at Epoch 328/500; Loss: 3.102928416287565e-05\n",
      "Training Circuit at Epoch 329/500; Loss: 3.082315925229118e-05\n",
      "Training Circuit at Epoch 330/500; Loss: 3.061906620327459e-05\n",
      "Training Circuit at Epoch 331/500; Loss: 3.0416864698179502e-05\n",
      "Training Circuit at Epoch 332/500; Loss: 3.021642467804231e-05\n",
      "Training Circuit at Epoch 333/500; Loss: 3.0017625744727106e-05\n",
      "Training Circuit at Epoch 334/500; Loss: 2.982035657927984e-05\n",
      "Training Circuit at Epoch 335/500; Loss: 2.9624514398585156e-05\n",
      "Training Circuit at Epoch 336/500; Loss: 2.9430004424901846e-05\n",
      "Training Circuit at Epoch 337/500; Loss: 2.9236739388149857e-05\n",
      "Training Circuit at Epoch 338/500; Loss: 2.9044639053177335e-05\n",
      "Training Circuit at Epoch 339/500; Loss: 2.885362976801087e-05\n",
      "Training Circuit at Epoch 340/500; Loss: 2.8663644036641678e-05\n",
      "Training Circuit at Epoch 341/500; Loss: 2.847462011268398e-05\n",
      "Training Circuit at Epoch 342/500; Loss: 2.8286501620122806e-05\n",
      "Training Circuit at Epoch 343/500; Loss: 2.8099237178502712e-05\n",
      "Training Circuit at Epoch 344/500; Loss: 2.7912780065086906e-05\n",
      "Training Circuit at Epoch 345/500; Loss: 2.7727087899220848e-05\n",
      "Training Circuit at Epoch 346/500; Loss: 2.7542122316925877e-05\n",
      "Training Circuit at Epoch 347/500; Loss: 2.735784869312141e-05\n",
      "Training Circuit at Epoch 348/500; Loss: 2.7174235870397467e-05\n",
      "Training Circuit at Epoch 349/500; Loss: 2.6991255891339883e-05\n",
      "Training Circuit at Epoch 350/500; Loss: 2.6808883771045622e-05\n",
      "Training Circuit at Epoch 351/500; Loss: 2.6627097260201182e-05\n",
      "Training Circuit at Epoch 352/500; Loss: 2.644587664091258e-05\n",
      "Training Circuit at Epoch 353/500; Loss: 2.6265204513431506e-05\n",
      "Training Circuit at Epoch 354/500; Loss: 2.608506562706836e-05\n",
      "Training Circuit at Epoch 355/500; Loss: 2.590544669500705e-05\n",
      "Training Circuit at Epoch 356/500; Loss: 2.5726336228881763e-05\n",
      "Training Circuit at Epoch 357/500; Loss: 2.554772440077624e-05\n",
      "Training Circuit at Epoch 358/500; Loss: 2.536960288335166e-05\n",
      "Training Circuit at Epoch 359/500; Loss: 2.5191964728721317e-05\n",
      "Training Circuit at Epoch 360/500; Loss: 2.5014804249212652e-05\n",
      "Training Circuit at Epoch 361/500; Loss: 2.4838116890579798e-05\n",
      "Training Circuit at Epoch 362/500; Loss: 2.466189913852279e-05\n",
      "Training Circuit at Epoch 363/500; Loss: 2.4486148414770703e-05\n",
      "Training Circuit at Epoch 364/500; Loss: 2.4310862991594462e-05\n",
      "Training Circuit at Epoch 365/500; Loss: 2.4136041899325278e-05\n",
      "Training Circuit at Epoch 366/500; Loss: 2.396168486118455e-05\n",
      "Training Circuit at Epoch 367/500; Loss: 2.3787792214902126e-05\n",
      "Training Circuit at Epoch 368/500; Loss: 2.36143648475462e-05\n",
      "Training Circuit at Epoch 369/500; Loss: 2.3441404142232614e-05\n",
      "Training Circuit at Epoch 370/500; Loss: 2.326891191484215e-05\n",
      "Training Circuit at Epoch 371/500; Loss: 2.3096890370277734e-05\n",
      "Training Circuit at Epoch 372/500; Loss: 2.2925342056390186e-05\n",
      "Training Circuit at Epoch 373/500; Loss: 2.2754269819902362e-05\n",
      "Training Circuit at Epoch 374/500; Loss: 2.2583676765886018e-05\n",
      "Training Circuit at Epoch 375/500; Loss: 2.241356623566837e-05\n",
      "Training Circuit at Epoch 376/500; Loss: 2.2243941758759433e-05\n",
      "Training Circuit at Epoch 377/500; Loss: 2.207480703841913e-05\n",
      "Training Circuit at Epoch 378/500; Loss: 2.1906165921570242e-05\n",
      "Training Circuit at Epoch 379/500; Loss: 2.1738022371153853e-05\n",
      "Training Circuit at Epoch 380/500; Loss: 2.1570380457358596e-05\n",
      "Training Circuit at Epoch 381/500; Loss: 2.140324432509111e-05\n",
      "Training Circuit at Epoch 382/500; Loss: 2.1236618191755596e-05\n",
      "Training Circuit at Epoch 383/500; Loss: 2.107050631994234e-05\n",
      "Training Circuit at Epoch 384/500; Loss: 2.0904913013652937e-05\n",
      "Training Circuit at Epoch 385/500; Loss: 2.073984260242412e-05\n",
      "Training Circuit at Epoch 386/500; Loss: 2.0575299436997874e-05\n",
      "Training Circuit at Epoch 387/500; Loss: 2.0411287868449257e-05\n",
      "Training Circuit at Epoch 388/500; Loss: 2.0247812254958752e-05\n",
      "Training Circuit at Epoch 389/500; Loss: 2.0084876944159724e-05\n",
      "Training Circuit at Epoch 390/500; Loss: 1.992248627136206e-05\n",
      "Training Circuit at Epoch 391/500; Loss: 1.9760644558108886e-05\n",
      "Training Circuit at Epoch 392/500; Loss: 1.959935610074126e-05\n",
      "Training Circuit at Epoch 393/500; Loss: 1.943862517272965e-05\n",
      "Training Circuit at Epoch 394/500; Loss: 1.9278456019566903e-05\n",
      "Training Circuit at Epoch 395/500; Loss: 1.9118852850108503e-05\n",
      "Training Circuit at Epoch 396/500; Loss: 1.8959819845232317e-05\n",
      "Training Circuit at Epoch 397/500; Loss: 1.880136115250952e-05\n",
      "Training Circuit at Epoch 398/500; Loss: 1.8643480876878726e-05\n",
      "Training Circuit at Epoch 399/500; Loss: 1.848618308641914e-05\n",
      "Training Circuit at Epoch 400/500; Loss: 1.8329471818345766e-05\n",
      "Training Circuit at Epoch 401/500; Loss: 1.8173351056804954e-05\n",
      "Training Circuit at Epoch 402/500; Loss: 1.801782475707725e-05\n",
      "Training Circuit at Epoch 403/500; Loss: 1.7862896829701214e-05\n",
      "Training Circuit at Epoch 404/500; Loss: 1.7708571141361595e-05\n",
      "Training Circuit at Epoch 405/500; Loss: 1.755485152421521e-05\n",
      "Training Circuit at Epoch 406/500; Loss: 1.7401741760458833e-05\n",
      "Training Circuit at Epoch 407/500; Loss: 1.7249245595984952e-05\n",
      "Training Circuit at Epoch 408/500; Loss: 1.709736673705109e-05\n",
      "Training Circuit at Epoch 409/500; Loss: 1.6946108841175977e-05\n",
      "Training Circuit at Epoch 410/500; Loss: 1.67954755307953e-05\n",
      "Training Circuit at Epoch 411/500; Loss: 1.66454703838248e-05\n",
      "Training Circuit at Epoch 412/500; Loss: 1.649609693388232e-05\n",
      "Training Circuit at Epoch 413/500; Loss: 1.634735867639403e-05\n",
      "Training Circuit at Epoch 414/500; Loss: 1.6199259063709448e-05\n",
      "Training Circuit at Epoch 415/500; Loss: 1.6051801504990415e-05\n",
      "Training Circuit at Epoch 416/500; Loss: 1.5904989370985056e-05\n",
      "Training Circuit at Epoch 417/500; Loss: 1.575882598825462e-05\n",
      "Training Circuit at Epoch 418/500; Loss: 1.5613314638063258e-05\n",
      "Training Circuit at Epoch 419/500; Loss: 1.5468458562928333e-05\n",
      "Training Circuit at Epoch 420/500; Loss: 1.5324260961069314e-05\n",
      "Training Circuit at Epoch 421/500; Loss: 1.518072499184786e-05\n",
      "Training Circuit at Epoch 422/500; Loss: 1.503785376810729e-05\n",
      "Training Circuit at Epoch 423/500; Loss: 1.4895650360946533e-05\n",
      "Training Circuit at Epoch 424/500; Loss: 1.4754117797166622e-05\n",
      "Training Circuit at Epoch 425/500; Loss: 1.46132590598258e-05\n",
      "Training Circuit at Epoch 426/500; Loss: 1.4473077091459174e-05\n",
      "Training Circuit at Epoch 427/500; Loss: 1.4333574787528391e-05\n",
      "Training Circuit at Epoch 428/500; Loss: 1.4194754999086179e-05\n",
      "Training Circuit at Epoch 429/500; Loss: 1.4056620534885766e-05\n",
      "Training Circuit at Epoch 430/500; Loss: 1.3919174156273861e-05\n",
      "Training Circuit at Epoch 431/500; Loss: 1.3782418580854383e-05\n",
      "Training Circuit at Epoch 432/500; Loss: 1.3646356481267219e-05\n",
      "Training Circuit at Epoch 433/500; Loss: 1.3510990482301644e-05\n",
      "Training Circuit at Epoch 434/500; Loss: 1.3376323163893922e-05\n",
      "Training Circuit at Epoch 435/500; Loss: 1.3242357059350951e-05\n",
      "Training Circuit at Epoch 436/500; Loss: 1.3109094653129816e-05\n",
      "Training Circuit at Epoch 437/500; Loss: 1.2976538388609349e-05\n",
      "Training Circuit at Epoch 438/500; Loss: 1.2844690651880875e-05\n",
      "Training Circuit at Epoch 439/500; Loss: 1.2713553791954268e-05\n",
      "Training Circuit at Epoch 440/500; Loss: 1.2583130100440876e-05\n",
      "Training Circuit at Epoch 441/500; Loss: 1.2453421824765165e-05\n",
      "Training Circuit at Epoch 442/500; Loss: 1.2324431164167926e-05\n",
      "Training Circuit at Epoch 443/500; Loss: 1.2196160265043332e-05\n",
      "Training Circuit at Epoch 444/500; Loss: 1.2068611230264814e-05\n",
      "Training Circuit at Epoch 445/500; Loss: 1.1941786105862384e-05\n",
      "Training Circuit at Epoch 446/500; Loss: 1.1815686894012245e-05\n",
      "Training Circuit at Epoch 447/500; Loss: 1.1690315542045582e-05\n",
      "Training Circuit at Epoch 448/500; Loss: 1.1565673947000477e-05\n",
      "Training Circuit at Epoch 449/500; Loss: 1.1441763962283247e-05\n",
      "Training Circuit at Epoch 450/500; Loss: 1.1318587378017497e-05\n",
      "Training Circuit at Epoch 451/500; Loss: 1.1196145939473823e-05\n",
      "Training Circuit at Epoch 452/500; Loss: 1.1074441342406871e-05\n",
      "Training Circuit at Epoch 453/500; Loss: 1.0953475225061737e-05\n",
      "Training Circuit at Epoch 454/500; Loss: 1.083324917616757e-05\n",
      "Training Circuit at Epoch 455/500; Loss: 1.0713764732273034e-05\n",
      "Training Circuit at Epoch 456/500; Loss: 1.0595023375192802e-05\n",
      "Training Circuit at Epoch 457/500; Loss: 1.0477026537558665e-05\n",
      "Training Circuit at Epoch 458/500; Loss: 1.0359775593937748e-05\n",
      "Training Circuit at Epoch 459/500; Loss: 1.0243271868937143e-05\n",
      "Training Circuit at Epoch 460/500; Loss: 1.0127516630986655e-05\n",
      "Training Circuit at Epoch 461/500; Loss: 1.0012511096557652e-05\n",
      "Training Circuit at Epoch 462/500; Loss: 9.898256429052843e-06\n",
      "Training Circuit at Epoch 463/500; Loss: 9.784753733699247e-06\n",
      "Training Circuit at Epoch 464/500; Loss: 9.672004062766248e-06\n",
      "Training Circuit at Epoch 465/500; Loss: 9.560008418119104e-06\n",
      "Training Circuit at Epoch 466/500; Loss: 9.44876774089387e-06\n",
      "Training Circuit at Epoch 467/500; Loss: 9.338282922266572e-06\n",
      "Training Circuit at Epoch 468/500; Loss: 9.228554791795851e-06\n",
      "Training Circuit at Epoch 469/500; Loss: 9.119584129191338e-06\n",
      "Training Circuit at Epoch 470/500; Loss: 9.01137165898458e-06\n",
      "Training Circuit at Epoch 471/500; Loss: 8.90391804542201e-06\n",
      "Training Circuit at Epoch 472/500; Loss: 8.797223902345941e-06\n",
      "Training Circuit at Epoch 473/500; Loss: 8.691289785756062e-06\n",
      "Training Circuit at Epoch 474/500; Loss: 8.586116191255933e-06\n",
      "Training Circuit at Epoch 475/500; Loss: 8.48170356815281e-06\n",
      "Training Circuit at Epoch 476/500; Loss: 8.378052299695682e-06\n",
      "Training Circuit at Epoch 477/500; Loss: 8.275162718063278e-06\n",
      "Training Circuit at Epoch 478/500; Loss: 8.173035096370462e-06\n",
      "Training Circuit at Epoch 479/500; Loss: 8.071669655329572e-06\n",
      "Training Circuit at Epoch 480/500; Loss: 7.9710665547017e-06\n",
      "Training Circuit at Epoch 481/500; Loss: 7.871225899069856e-06\n",
      "Training Circuit at Epoch 482/500; Loss: 7.772147739393276e-06\n",
      "Training Circuit at Epoch 483/500; Loss: 7.673832063015418e-06\n",
      "Training Circuit at Epoch 484/500; Loss: 7.576278807763792e-06\n",
      "Training Circuit at Epoch 485/500; Loss: 7.479487848849331e-06\n",
      "Training Circuit at Epoch 486/500; Loss: 7.383459007748172e-06\n",
      "Training Circuit at Epoch 487/500; Loss: 7.288192049537123e-06\n",
      "Training Circuit at Epoch 488/500; Loss: 7.193686677675615e-06\n",
      "Training Circuit at Epoch 489/500; Loss: 7.099942546662241e-06\n",
      "Training Circuit at Epoch 490/500; Loss: 7.006959244493238e-06\n",
      "Training Circuit at Epoch 491/500; Loss: 6.914736308316627e-06\n",
      "Training Circuit at Epoch 492/500; Loss: 6.823273216771675e-06\n",
      "Training Circuit at Epoch 493/500; Loss: 6.732569391876275e-06\n",
      "Training Circuit at Epoch 494/500; Loss: 6.642624198249791e-06\n",
      "Training Circuit at Epoch 495/500; Loss: 6.553436943557145e-06\n",
      "Training Circuit at Epoch 496/500; Loss: 6.465006878952906e-06\n",
      "Training Circuit at Epoch 497/500; Loss: 6.377333194751422e-06\n",
      "Training Circuit at Epoch 498/500; Loss: 6.29041503341643e-06\n",
      "Training Circuit at Epoch 499/500; Loss: 6.204251472796685e-06\n",
      "Training Circuit at Epoch 500/500; Loss: 6.118841533897523e-06\n"
     ]
    }
   ],
   "source": [
    "final_params, loss_list = circuitModelTuning(\n",
    "        initial_params=init_params,\n",
    "        model=model,\n",
    "        num_epochs=500,\n",
    "        k=intended_k,\n",
    "        op_pool=pool,\n",
    "        opt_callable=qml.AdamOptimizer,\n",
    "        lr=0.01,\n",
    "        grad_noise_factor=0,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53fa2cc1-9078-477d-8c0c-83f712eb8036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Circuit at Epoch 1/500; Loss: 0.7890995552640592\n",
      "Training Circuit at Epoch 2/500; Loss: 0.7797765540650926\n",
      "Training Circuit at Epoch 3/500; Loss: 0.7728940918325365\n",
      "Training Circuit at Epoch 4/500; Loss: 0.7670286325020674\n",
      "Training Circuit at Epoch 5/500; Loss: 0.7617217978754041\n",
      "Training Circuit at Epoch 6/500; Loss: 0.7567567192568349\n",
      "Training Circuit at Epoch 7/500; Loss: 0.7520100677671261\n",
      "Training Circuit at Epoch 8/500; Loss: 0.7474037376994305\n",
      "Training Circuit at Epoch 9/500; Loss: 0.7428846048604631\n",
      "Training Circuit at Epoch 10/500; Loss: 0.7384146249332275\n",
      "Training Circuit at Epoch 11/500; Loss: 0.7339654864291901\n",
      "Training Circuit at Epoch 12/500; Loss: 0.7295155170702767\n",
      "Training Circuit at Epoch 13/500; Loss: 0.7250477865780601\n",
      "Training Circuit at Epoch 14/500; Loss: 0.7205488739017636\n",
      "Training Circuit at Epoch 15/500; Loss: 0.7160080169907866\n",
      "Training Circuit at Epoch 16/500; Loss: 0.7114164915489908\n",
      "Training Circuit at Epoch 17/500; Loss: 0.7067671337623491\n",
      "Training Circuit at Epoch 18/500; Loss: 0.7020539592163921\n",
      "Training Circuit at Epoch 19/500; Loss: 0.6972718503946153\n",
      "Training Circuit at Epoch 20/500; Loss: 0.692416295847434\n",
      "Training Circuit at Epoch 21/500; Loss: 0.6874831694780263\n",
      "Training Circuit at Epoch 22/500; Loss: 0.6824685407248452\n",
      "Training Circuit at Epoch 23/500; Loss: 0.6773685071262996\n",
      "Training Circuit at Epoch 24/500; Loss: 0.6721790408020856\n",
      "Training Circuit at Epoch 25/500; Loss: 0.6668958405585518\n",
      "Training Circuit at Epoch 26/500; Loss: 0.6615141822586859\n",
      "Training Circuit at Epoch 27/500; Loss: 0.6560287622197518\n",
      "Training Circuit at Epoch 28/500; Loss: 0.6504335318478978\n",
      "Training Circuit at Epoch 29/500; Loss: 0.6447215262913754\n",
      "Training Circuit at Epoch 30/500; Loss: 0.6388846950997958\n",
      "Training Circuit at Epoch 31/500; Loss: 0.6329137480184424\n",
      "Training Circuit at Epoch 32/500; Loss: 0.6267980333170777\n",
      "Training Circuit at Epoch 33/500; Loss: 0.6205254686107158\n",
      "Training Circuit at Epoch 34/500; Loss: 0.6140825441762374\n",
      "Training Circuit at Epoch 35/500; Loss: 0.6074544156791306\n",
      "Training Circuit at Epoch 36/500; Loss: 0.600625096779033\n",
      "Training Circuit at Epoch 37/500; Loss: 0.5935777527484923\n",
      "Training Circuit at Epoch 38/500; Loss: 0.5862950853501367\n",
      "Training Circuit at Epoch 39/500; Loss: 0.5787597888389611\n",
      "Training Circuit at Epoch 40/500; Loss: 0.5709550493411473\n",
      "Training Circuit at Epoch 41/500; Loss: 0.5628650566611288\n",
      "Training Circuit at Epoch 42/500; Loss: 0.5544754992081768\n",
      "Training Circuit at Epoch 43/500; Loss: 0.5457740182993531\n",
      "Training Circuit at Epoch 44/500; Loss: 0.5367506057966215\n",
      "Training Circuit at Epoch 45/500; Loss: 0.527397936935621\n",
      "Training Circuit at Epoch 46/500; Loss: 0.5177116368321885\n",
      "Training Circuit at Epoch 47/500; Loss: 0.507690483771942\n",
      "Training Circuit at Epoch 48/500; Loss: 0.4973365549220248\n",
      "Training Circuit at Epoch 49/500; Loss: 0.48665532088965824\n",
      "Training Circuit at Epoch 50/500; Loss: 0.47565569507744854\n",
      "Training Circuit at Epoch 51/500; Loss: 0.46435004251075507\n",
      "Training Circuit at Epoch 52/500; Loss: 0.45275415109826056\n",
      "Training Circuit at Epoch 53/500; Loss: 0.44088716640043857\n",
      "Training Circuit at Epoch 54/500; Loss: 0.4287714891369393\n",
      "Training Circuit at Epoch 55/500; Loss: 0.41643263306085254\n",
      "Training Circuit at Epoch 56/500; Loss: 0.40389903965116003\n",
      "Training Circuit at Epoch 57/500; Loss: 0.3912018454706949\n",
      "Training Circuit at Epoch 58/500; Loss: 0.3783745980706028\n",
      "Training Circuit at Epoch 59/500; Loss: 0.3654529169542431\n",
      "Training Circuit at Epoch 60/500; Loss: 0.3524740972285846\n",
      "Training Circuit at Epoch 61/500; Loss: 0.3394766550716847\n",
      "Training Circuit at Epoch 62/500; Loss: 0.3264998160849689\n",
      "Training Circuit at Epoch 63/500; Loss: 0.31358295029341665\n",
      "Training Circuit at Epoch 64/500; Loss: 0.3007649615728546\n",
      "Training Circuit at Epoch 65/500; Loss: 0.2880836452391491\n",
      "Training Circuit at Epoch 66/500; Loss: 0.27557503568807795\n",
      "Training Circuit at Epoch 67/500; Loss: 0.26327277570758445\n",
      "Training Circuit at Epoch 68/500; Loss: 0.2512075484928391\n",
      "Training Circuit at Epoch 69/500; Loss: 0.2394066193189074\n",
      "Training Circuit at Epoch 70/500; Loss: 0.22789353260505307\n",
      "Training Circuit at Epoch 71/500; Loss: 0.21668799909518843\n",
      "Training Circuit at Epoch 72/500; Loss: 0.2058059872147321\n",
      "Training Circuit at Epoch 73/500; Loss: 0.19526000614885486\n",
      "Training Circuit at Epoch 74/500; Loss: 0.18505954223860854\n",
      "Training Circuit at Epoch 75/500; Loss: 0.17521159103309225\n",
      "Training Circuit at Epoch 76/500; Loss: 0.16572121766463144\n",
      "Training Circuit at Epoch 77/500; Loss: 0.15659207721867952\n",
      "Training Circuit at Epoch 78/500; Loss: 0.1478268321073053\n",
      "Training Circuit at Epoch 79/500; Loss: 0.13942741453733987\n",
      "Training Circuit at Epoch 80/500; Loss: 0.13139510102413499\n",
      "Training Circuit at Epoch 81/500; Loss: 0.12373039455717072\n",
      "Training Circuit at Epoch 82/500; Loss: 0.11643274640036694\n",
      "Training Circuit at Epoch 83/500; Loss: 0.10950018556009822\n",
      "Training Circuit at Epoch 84/500; Loss: 0.1029289480833454\n",
      "Training Circuit at Epoch 85/500; Loss: 0.0967132009109467\n",
      "Training Circuit at Epoch 86/500; Loss: 0.09084493335162158\n",
      "Training Circuit at Epoch 87/500; Loss: 0.08531404929051545\n",
      "Training Circuit at Epoch 88/500; Loss: 0.08010864708029375\n",
      "Training Circuit at Epoch 89/500; Loss: 0.07521543508278405\n",
      "Training Circuit at Epoch 90/500; Loss: 0.07062020892911591\n",
      "Training Circuit at Epoch 91/500; Loss: 0.06630831520709057\n",
      "Training Circuit at Epoch 92/500; Loss: 0.062265042266828496\n",
      "Training Circuit at Epoch 93/500; Loss: 0.05847590446871476\n",
      "Training Circuit at Epoch 94/500; Loss: 0.05492681272780242\n",
      "Training Circuit at Epoch 95/500; Loss: 0.051604145011320046\n",
      "Training Circuit at Epoch 96/500; Loss: 0.048494742697899884\n",
      "Training Circuit at Epoch 97/500; Loss: 0.04558586305867984\n",
      "Training Circuit at Epoch 98/500; Loss: 0.04286511694663264\n",
      "Training Circuit at Epoch 99/500; Loss: 0.04032041631198302\n",
      "Training Circuit at Epoch 100/500; Loss: 0.03793994961549996\n",
      "Training Circuit at Epoch 101/500; Loss: 0.035712195112731715\n",
      "Training Circuit at Epoch 102/500; Loss: 0.033625972979068\n",
      "Training Circuit at Epoch 103/500; Loss: 0.031670528580362234\n",
      "Training Circuit at Epoch 104/500; Loss: 0.029835632517491772\n",
      "Training Circuit at Epoch 105/500; Loss: 0.028111679857770966\n",
      "Training Circuit at Epoch 106/500; Loss: 0.0264897719382009\n",
      "Training Circuit at Epoch 107/500; Loss: 0.024961768958898678\n",
      "Training Circuit at Epoch 108/500; Loss: 0.023520308903434817\n",
      "Training Circuit at Epoch 109/500; Loss: 0.022158795999592473\n",
      "Training Circuit at Epoch 110/500; Loss: 0.020871367671305152\n",
      "Training Circuit at Epoch 111/500; Loss: 0.019652851011609185\n",
      "Training Circuit at Epoch 112/500; Loss: 0.018498717752779115\n",
      "Training Circuit at Epoch 113/500; Loss: 0.017405041550110356\n",
      "Training Circuit at Epoch 114/500; Loss: 0.01636845532576303\n",
      "Training Circuit at Epoch 115/500; Loss: 0.015386101970882082\n",
      "Training Circuit at Epoch 116/500; Loss: 0.014455570761069847\n",
      "Training Circuit at Epoch 117/500; Loss: 0.013574814910423671\n",
      "Training Circuit at Epoch 118/500; Loss: 0.012742051729864423\n",
      "Training Circuit at Epoch 119/500; Loss: 0.011955653685755463\n",
      "Training Circuit at Epoch 120/500; Loss: 0.011214043772892035\n",
      "Training Circuit at Epoch 121/500; Loss: 0.010515610098059902\n",
      "Training Circuit at Epoch 122/500; Loss: 0.009858651734545587\n",
      "Training Circuit at Epoch 123/500; Loss: 0.00924136152450794\n",
      "Training Circuit at Epoch 124/500; Loss: 0.00866184350150001\n",
      "Training Circuit at Epoch 125/500; Loss: 0.00811815537575089\n",
      "Training Circuit at Epoch 126/500; Loss: 0.007608362115494205\n",
      "Training Circuit at Epoch 127/500; Loss: 0.007130586111459447\n",
      "Training Circuit at Epoch 128/500; Loss: 0.006683042517447668\n",
      "Training Circuit at Epoch 129/500; Loss: 0.006264053860707497\n",
      "Training Circuit at Epoch 130/500; Loss: 0.005872044140975086\n",
      "Training Circuit at Epoch 131/500; Loss: 0.005505517714829877\n",
      "Training Circuit at Epoch 132/500; Loss: 0.00516303118348449\n",
      "Training Circuit at Epoch 133/500; Loss: 0.00484316691830855\n",
      "Training Circuit at Epoch 134/500; Loss: 0.004544515118535708\n",
      "Training Circuit at Epoch 135/500; Loss: 0.00426566821277008\n",
      "Training Circuit at Epoch 136/500; Loss: 0.004005227967650238\n",
      "Training Circuit at Epoch 137/500; Loss: 0.003761822723456487\n",
      "Training Circuit at Epoch 138/500; Loss: 0.003534130314605366\n",
      "Training Circuit at Epoch 139/500; Loss: 0.003320901663935949\n",
      "Training Circuit at Epoch 140/500; Loss: 0.00312098063912547\n",
      "Training Circuit at Epoch 141/500; Loss: 0.0029333171696730442\n",
      "Training Circuit at Epoch 142/500; Loss: 0.002756972381505629\n",
      "Training Circuit at Epoch 143/500; Loss: 0.0025911161670745253\n",
      "Training Circuit at Epoch 144/500; Loss: 0.002435018831844493\n",
      "Training Circuit at Epoch 145/500; Loss: 0.002288039063037761\n",
      "Training Circuit at Epoch 146/500; Loss: 0.002149610448768602\n",
      "Training Circuit at Epoch 147/500; Loss: 0.0020192282846152043\n",
      "Training Circuit at Epoch 148/500; Loss: 0.0018964376875578726\n",
      "Training Circuit at Epoch 149/500; Loss: 0.0017808233592726541\n",
      "Training Circuit at Epoch 150/500; Loss: 0.001672000901745796\n",
      "Training Circuit at Epoch 151/500; Loss: 0.0015696094635895275\n",
      "Training Circuit at Epoch 152/500; Loss: 0.0014733056241171827\n",
      "Training Circuit at Epoch 153/500; Loss: 0.0013827586462692443\n",
      "Training Circuit at Epoch 154/500; Loss: 0.0012976473712504877\n",
      "Training Circuit at Epoch 155/500; Loss: 0.0012176589703912777\n",
      "Training Circuit at Epoch 156/500; Loss: 0.0011424895067961849\n",
      "Training Circuit at Epoch 157/500; Loss: 0.0010718458925566\n",
      "Training Circuit at Epoch 158/500; Loss: 0.0010054485148194292\n",
      "Training Circuit at Epoch 159/500; Loss: 0.0009430336856359745\n",
      "Training Circuit at Epoch 160/500; Loss: 0.0008843552039839997\n",
      "Training Circuit at Epoch 161/500; Loss: 0.0008291846565092742\n",
      "Training Circuit at Epoch 162/500; Loss: 0.0007773104985326906\n",
      "Training Circuit at Epoch 163/500; Loss: 0.0007285362994395861\n",
      "Training Circuit at Epoch 164/500; Loss: 0.0006826786988738398\n",
      "Training Circuit at Epoch 165/500; Loss: 0.000639565575708767\n",
      "Training Circuit at Epoch 166/500; Loss: 0.0005990347353351799\n",
      "Training Circuit at Epoch 167/500; Loss: 0.0005609331745147772\n",
      "Training Circuit at Epoch 168/500; Loss: 0.0005251167865286677\n",
      "Training Circuit at Epoch 169/500; Loss: 0.0004914502799927556\n",
      "Training Circuit at Epoch 170/500; Loss: 0.00045980710289972304\n",
      "Training Circuit at Epoch 171/500; Loss: 0.00043006924620669906\n",
      "Training Circuit at Epoch 172/500; Loss: 0.0004021268921995391\n",
      "Training Circuit at Epoch 173/500; Loss: 0.00037587793112003887\n",
      "Training Circuit at Epoch 174/500; Loss: 0.0003512273848873537\n",
      "Training Circuit at Epoch 175/500; Loss: 0.0003280867650116148\n",
      "Training Circuit at Epoch 176/500; Loss: 0.0003063733789772094\n",
      "Training Circuit at Epoch 177/500; Loss: 0.00028600960315372514\n",
      "Training Circuit at Epoch 178/500; Loss: 0.00026692216114965195\n",
      "Training Circuit at Epoch 179/500; Loss: 0.0002490414701167287\n",
      "Training Circuit at Epoch 180/500; Loss: 0.00023230112544248005\n",
      "Training Circuit at Epoch 181/500; Loss: 0.00021663757581524834\n",
      "Training Circuit at Epoch 182/500; Loss: 0.00020198999883158653\n",
      "Training Circuit at Epoch 183/500; Loss: 0.00018830033693462145\n",
      "Training Circuit at Epoch 184/500; Loss: 0.00017551341360078077\n",
      "Training Circuit at Epoch 185/500; Loss: 0.00016357703468450335\n",
      "Training Circuit at Epoch 186/500; Loss: 0.00015244199438579908\n",
      "Training Circuit at Epoch 187/500; Loss: 0.00014206194324439814\n",
      "Training Circuit at Epoch 188/500; Loss: 0.00013239312375701306\n",
      "Training Circuit at Epoch 189/500; Loss: 0.00012339402232453\n",
      "Training Circuit at Epoch 190/500; Loss: 0.0001150250120123264\n",
      "Training Circuit at Epoch 191/500; Loss: 0.00010724806226791728\n",
      "Training Circuit at Epoch 192/500; Loss: 0.00010002657048280295\n",
      "Training Circuit at Epoch 193/500; Loss: 9.3325333353933e-05\n",
      "Training Circuit at Epoch 194/500; Loss: 8.711063573374478e-05\n",
      "Training Circuit at Epoch 195/500; Loss: 8.135040366419322e-05\n",
      "Training Circuit at Epoch 196/500; Loss: 7.601435600501638e-05\n",
      "Training Circuit at Epoch 197/500; Loss: 7.10740979551483e-05\n",
      "Training Circuit at Epoch 198/500; Loss: 6.650312493128308e-05\n",
      "Training Circuit at Epoch 199/500; Loss: 6.227673615732954e-05\n",
      "Training Circuit at Epoch 200/500; Loss: 5.837188277479921e-05\n",
      "Training Circuit at Epoch 201/500; Loss: 5.4766987489185404e-05\n",
      "Training Circuit at Epoch 202/500; Loss: 5.144177051707999e-05\n",
      "Training Circuit at Epoch 203/500; Loss: 4.837710427496589e-05\n",
      "Training Circuit at Epoch 204/500; Loss: 4.5554904268718666e-05\n",
      "Training Circuit at Epoch 205/500; Loss: 4.295805228005101e-05\n",
      "Training Circuit at Epoch 206/500; Loss: 4.0570342915713375e-05\n",
      "Training Circuit at Epoch 207/500; Loss: 3.8376444972954005e-05\n",
      "Training Circuit at Epoch 208/500; Loss: 3.636187177458172e-05\n",
      "Training Circuit at Epoch 209/500; Loss: 3.451295695033885e-05\n",
      "Training Circuit at Epoch 210/500; Loss: 3.28168330657741e-05\n",
      "Training Circuit at Epoch 211/500; Loss: 3.12614105527631e-05\n",
      "Training Circuit at Epoch 212/500; Loss: 2.9835354792062674e-05\n",
      "Training Circuit at Epoch 213/500; Loss: 2.8528060381338705e-05\n",
      "Training Circuit at Epoch 214/500; Loss: 2.7329623221161725e-05\n",
      "Training Circuit at Epoch 215/500; Loss: 2.623081204777833e-05\n",
      "Training Circuit at Epoch 216/500; Loss: 2.522304093133254e-05\n",
      "Training Circuit at Epoch 217/500; Loss: 2.4298343157536095e-05\n",
      "Training Circuit at Epoch 218/500; Loss: 2.3449345649462217e-05\n",
      "Training Circuit at Epoch 219/500; Loss: 2.2669242470407802e-05\n",
      "Training Circuit at Epoch 220/500; Loss: 2.1951766231764758e-05\n",
      "Training Circuit at Epoch 221/500; Loss: 2.1291157042746534e-05\n",
      "Training Circuit at Epoch 222/500; Loss: 2.0682129516225167e-05\n",
      "Training Circuit at Epoch 223/500; Loss: 2.0119838712640004e-05\n",
      "Training Circuit at Epoch 224/500; Loss: 1.9599846018736322e-05\n",
      "Training Circuit at Epoch 225/500; Loss: 1.911808586740893e-05\n",
      "Training Circuit at Epoch 226/500; Loss: 1.8670834273648573e-05\n",
      "Training Circuit at Epoch 227/500; Loss: 1.8254680256624134e-05\n",
      "Training Circuit at Epoch 228/500; Loss: 1.7866501054730755e-05\n",
      "Training Circuit at Epoch 229/500; Loss: 1.7503441624655558e-05\n",
      "Training Circuit at Epoch 230/500; Loss: 1.7162897987921255e-05\n",
      "Training Circuit at Epoch 231/500; Loss: 1.6842503242631146e-05\n",
      "Training Circuit at Epoch 232/500; Loss: 1.654011451690529e-05\n",
      "Training Circuit at Epoch 233/500; Loss: 1.6253799277388126e-05\n",
      "Training Circuit at Epoch 234/500; Loss: 1.5981820021826465e-05\n",
      "Training Circuit at Epoch 235/500; Loss: 1.5722617272895256e-05\n",
      "Training Circuit at Epoch 236/500; Loss: 1.547479166208454e-05\n",
      "Training Circuit at Epoch 237/500; Loss: 1.5237086418262713e-05\n",
      "Training Circuit at Epoch 238/500; Loss: 1.5008371700653278e-05\n",
      "Training Circuit at Epoch 239/500; Loss: 1.4787631815615931e-05\n",
      "Training Circuit at Epoch 240/500; Loss: 1.4573955698482521e-05\n",
      "Training Circuit at Epoch 241/500; Loss: 1.436653014708078e-05\n",
      "Training Circuit at Epoch 242/500; Loss: 1.416463468517648e-05\n",
      "Training Circuit at Epoch 243/500; Loss: 1.3967636667056027e-05\n",
      "Training Circuit at Epoch 244/500; Loss: 1.3774985518910654e-05\n",
      "Training Circuit at Epoch 245/500; Loss: 1.358620566160873e-05\n",
      "Training Circuit at Epoch 246/500; Loss: 1.3400888339232253e-05\n",
      "Training Circuit at Epoch 247/500; Loss: 1.3218683071025694e-05\n",
      "Training Circuit at Epoch 248/500; Loss: 1.3039289505023532e-05\n",
      "Training Circuit at Epoch 249/500; Loss: 1.2862450248674051e-05\n",
      "Training Circuit at Epoch 250/500; Loss: 1.2687944850875432e-05\n",
      "Training Circuit at Epoch 251/500; Loss: 1.2515584867811569e-05\n",
      "Training Circuit at Epoch 252/500; Loss: 1.2345209789099698e-05\n",
      "Training Circuit at Epoch 253/500; Loss: 1.2176683579556702e-05\n",
      "Training Circuit at Epoch 254/500; Loss: 1.2009891671715955e-05\n",
      "Training Circuit at Epoch 255/500; Loss: 1.1844738277866362e-05\n",
      "Training Circuit at Epoch 256/500; Loss: 1.1681143945230232e-05\n",
      "Training Circuit at Epoch 257/500; Loss: 1.1519043330743273e-05\n",
      "Training Circuit at Epoch 258/500; Loss: 1.135838323673699e-05\n",
      "Training Circuit at Epoch 259/500; Loss: 1.1199120936167262e-05\n",
      "Training Circuit at Epoch 260/500; Loss: 1.1041222825802777e-05\n",
      "Training Circuit at Epoch 261/500; Loss: 1.0884663315779974e-05\n",
      "Training Circuit at Epoch 262/500; Loss: 1.072942387247977e-05\n",
      "Training Circuit at Epoch 263/500; Loss: 1.0575492058850777e-05\n",
      "Training Circuit at Epoch 264/500; Loss: 1.0422860536096756e-05\n",
      "Training Circuit at Epoch 265/500; Loss: 1.0271526015404042e-05\n",
      "Training Circuit at Epoch 266/500; Loss: 1.012148825596526e-05\n",
      "Training Circuit at Epoch 267/500; Loss: 9.972749187681096e-06\n",
      "Training Circuit at Epoch 268/500; Loss: 9.825312207500936e-06\n",
      "Training Circuit at Epoch 269/500; Loss: 9.679181670385617e-06\n",
      "Training Circuit at Epoch 270/500; Loss: 9.534362530261298e-06\n",
      "Training Circuit at Epoch 271/500; Loss: 9.390860085667363e-06\n",
      "Training Circuit at Epoch 272/500; Loss: 9.248679790907488e-06\n",
      "Training Circuit at Epoch 273/500; Loss: 9.107827099286148e-06\n",
      "Training Circuit at Epoch 274/500; Loss: 8.968307324108693e-06\n",
      "Training Circuit at Epoch 275/500; Loss: 8.830125506120723e-06\n",
      "Training Circuit at Epoch 276/500; Loss: 8.693286282501766e-06\n",
      "Training Circuit at Epoch 277/500; Loss: 8.557793743868558e-06\n",
      "Training Circuit at Epoch 278/500; Loss: 8.423651311817437e-06\n",
      "Training Circuit at Epoch 279/500; Loss: 8.290861622128887e-06\n",
      "Training Circuit at Epoch 280/500; Loss: 8.159426472698073e-06\n",
      "Training Circuit at Epoch 281/500; Loss: 8.029346832638673e-06\n",
      "Training Circuit at Epoch 282/500; Loss: 7.900622928103118e-06\n",
      "Training Circuit at Epoch 283/500; Loss: 7.773254369292104e-06\n",
      "Training Circuit at Epoch 284/500; Loss: 7.647240282238066e-06\n",
      "Training Circuit at Epoch 285/500; Loss: 7.522579389518391e-06\n",
      "Training Circuit at Epoch 286/500; Loss: 7.399270032792948e-06\n",
      "Training Circuit at Epoch 287/500; Loss: 7.277310146047711e-06\n",
      "Training Circuit at Epoch 288/500; Loss: 7.156697221732955e-06\n",
      "Training Circuit at Epoch 289/500; Loss: 7.037428288114711e-06\n",
      "Training Circuit at Epoch 290/500; Loss: 6.91949992315255e-06\n",
      "Training Circuit at Epoch 291/500; Loss: 6.802908288250364e-06\n",
      "Training Circuit at Epoch 292/500; Loss: 6.68764917755027e-06\n",
      "Training Circuit at Epoch 293/500; Loss: 6.573718054569966e-06\n",
      "Training Circuit at Epoch 294/500; Loss: 6.461110093169964e-06\n",
      "Training Circuit at Epoch 295/500; Loss: 6.349820201201339e-06\n",
      "Training Circuit at Epoch 296/500; Loss: 6.239843052036065e-06\n",
      "Training Circuit at Epoch 297/500; Loss: 6.131173102330578e-06\n",
      "Training Circuit at Epoch 298/500; Loss: 6.023804625998608e-06\n",
      "Training Circuit at Epoch 299/500; Loss: 5.917731731641673e-06\n",
      "Training Circuit at Epoch 300/500; Loss: 5.812948392414086e-06\n",
      "Training Circuit at Epoch 301/500; Loss: 5.709448466229006e-06\n",
      "Training Circuit at Epoch 302/500; Loss: 5.607225712522812e-06\n",
      "Training Circuit at Epoch 303/500; Loss: 5.506273806910045e-06\n",
      "Training Circuit at Epoch 304/500; Loss: 5.406586340739317e-06\n",
      "Training Circuit at Epoch 305/500; Loss: 5.3081568305302085e-06\n",
      "Training Circuit at Epoch 306/500; Loss: 5.210978706871039e-06\n",
      "Training Circuit at Epoch 307/500; Loss: 5.115045319747935e-06\n",
      "Training Circuit at Epoch 308/500; Loss: 5.020349946316394e-06\n",
      "Training Circuit at Epoch 309/500; Loss: 4.926885793898883e-06\n",
      "Training Circuit at Epoch 310/500; Loss: 4.8346460091996946e-06\n",
      "Training Circuit at Epoch 311/500; Loss: 4.743623682967879e-06\n",
      "Training Circuit at Epoch 312/500; Loss: 4.653811848998046e-06\n",
      "Training Circuit at Epoch 313/500; Loss: 4.565203480466629e-06\n",
      "Training Circuit at Epoch 314/500; Loss: 4.477791488710636e-06\n",
      "Training Circuit at Epoch 315/500; Loss: 4.391568719785965e-06\n",
      "Training Circuit at Epoch 316/500; Loss: 4.306527956909889e-06\n",
      "Training Circuit at Epoch 317/500; Loss: 4.222661913022563e-06\n",
      "Training Circuit at Epoch 318/500; Loss: 4.139963241778233e-06\n",
      "Training Circuit at Epoch 319/500; Loss: 4.058424526776072e-06\n",
      "Training Circuit at Epoch 320/500; Loss: 3.978038287999475e-06\n",
      "Training Circuit at Epoch 321/500; Loss: 3.898796979817654e-06\n",
      "Training Circuit at Epoch 322/500; Loss: 3.820692990541552e-06\n",
      "Training Circuit at Epoch 323/500; Loss: 3.7437186392041966e-06\n",
      "Training Circuit at Epoch 324/500; Loss: 3.667866176781942e-06\n",
      "Training Circuit at Epoch 325/500; Loss: 3.5931277770906433e-06\n",
      "Training Circuit at Epoch 326/500; Loss: 3.5194955391171234e-06\n",
      "Training Circuit at Epoch 327/500; Loss: 3.446961485464861e-06\n",
      "Training Circuit at Epoch 328/500; Loss: 3.3755175645744373e-06\n",
      "Training Circuit at Epoch 329/500; Loss: 3.3051556491692224e-06\n",
      "Training Circuit at Epoch 330/500; Loss: 3.2358675401411574e-06\n",
      "Training Circuit at Epoch 331/500; Loss: 3.1676449669948425e-06\n",
      "Training Circuit at Epoch 332/500; Loss: 3.100479583961757e-06\n",
      "Training Circuit at Epoch 333/500; Loss: 3.034362974663196e-06\n",
      "Training Circuit at Epoch 334/500; Loss: 2.9692866533315154e-06\n",
      "Training Circuit at Epoch 335/500; Loss: 2.905242064588087e-06\n",
      "Training Circuit at Epoch 336/500; Loss: 2.8422205876621476e-06\n",
      "Training Circuit at Epoch 337/500; Loss: 2.780213538056131e-06\n",
      "Training Circuit at Epoch 338/500; Loss: 2.719212168877938e-06\n",
      "Training Circuit at Epoch 339/500; Loss: 2.6592076717291135e-06\n",
      "Training Circuit at Epoch 340/500; Loss: 2.600191180035516e-06\n",
      "Training Circuit at Epoch 341/500; Loss: 2.5421537698244734e-06\n",
      "Training Circuit at Epoch 342/500; Loss: 2.4850864627223856e-06\n",
      "Training Circuit at Epoch 343/500; Loss: 2.4289802282861928e-06\n",
      "Training Circuit at Epoch 344/500; Loss: 2.3738259845584864e-06\n",
      "Training Circuit at Epoch 345/500; Loss: 2.319614602619424e-06\n",
      "Training Circuit at Epoch 346/500; Loss: 2.2663369104725106e-06\n",
      "Training Circuit at Epoch 347/500; Loss: 2.213983690935173e-06\n",
      "Training Circuit at Epoch 348/500; Loss: 2.1625456897433892e-06\n",
      "Training Circuit at Epoch 349/500; Loss: 2.1120136153296443e-06\n",
      "Training Circuit at Epoch 350/500; Loss: 2.062378139267018e-06\n",
      "Training Circuit at Epoch 351/500; Loss: 2.013629903041547e-06\n",
      "Training Circuit at Epoch 352/500; Loss: 1.9657595180522236e-06\n",
      "Training Circuit at Epoch 353/500; Loss: 1.9187575703849546e-06\n",
      "Training Circuit at Epoch 354/500; Loss: 1.8726146203684735e-06\n",
      "Training Circuit at Epoch 355/500; Loss: 1.8273212080144319e-06\n",
      "Training Circuit at Epoch 356/500; Loss: 1.782867853683534e-06\n",
      "Training Circuit at Epoch 357/500; Loss: 1.7392450615272281e-06\n",
      "Training Circuit at Epoch 358/500; Loss: 1.696443320930996e-06\n",
      "Training Circuit at Epoch 359/500; Loss: 1.6544531095119552e-06\n",
      "Training Circuit at Epoch 360/500; Loss: 1.6132648962274843e-06\n",
      "Training Circuit at Epoch 361/500; Loss: 1.5728691422634e-06\n",
      "Training Circuit at Epoch 362/500; Loss: 1.5332563059189397e-06\n",
      "Training Circuit at Epoch 363/500; Loss: 1.4944168408304037e-06\n",
      "Training Circuit at Epoch 364/500; Loss: 1.4563412025214717e-06\n",
      "Training Circuit at Epoch 365/500; Loss: 1.4190198499575146e-06\n",
      "Training Circuit at Epoch 366/500; Loss: 1.382443243769238e-06\n",
      "Training Circuit at Epoch 367/500; Loss: 1.3466018550234438e-06\n",
      "Training Circuit at Epoch 368/500; Loss: 1.3114861624474727e-06\n",
      "Training Circuit at Epoch 369/500; Loss: 1.277086657314186e-06\n",
      "Training Circuit at Epoch 370/500; Loss: 1.2433938442191206e-06\n",
      "Training Circuit at Epoch 371/500; Loss: 1.2103982433009364e-06\n",
      "Training Circuit at Epoch 372/500; Loss: 1.1780903944602628e-06\n",
      "Training Circuit at Epoch 373/500; Loss: 1.1464608558053868e-06\n",
      "Training Circuit at Epoch 374/500; Loss: 1.1155002103135914e-06\n",
      "Training Circuit at Epoch 375/500; Loss: 1.0851990639437759e-06\n",
      "Training Circuit at Epoch 376/500; Loss: 1.0555480478569024e-06\n",
      "Training Circuit at Epoch 377/500; Loss: 1.0265378252993784e-06\n",
      "Training Circuit at Epoch 378/500; Loss: 9.981590882723879e-07\n",
      "Training Circuit at Epoch 379/500; Loss: 9.704025603074484e-07\n",
      "Training Circuit at Epoch 380/500; Loss: 9.432590022395715e-07\n",
      "Training Circuit at Epoch 381/500; Loss: 9.167192092096599e-07\n",
      "Training Circuit at Epoch 382/500; Loss: 8.907740161046007e-07\n",
      "Training Circuit at Epoch 383/500; Loss: 8.654142976682877e-07\n",
      "Training Circuit at Epoch 384/500; Loss: 8.40630971388201e-07\n",
      "Training Circuit at Epoch 385/500; Loss: 8.16414998161541e-07\n",
      "Training Circuit at Epoch 386/500; Loss: 7.927573857369197e-07\n",
      "Training Circuit at Epoch 387/500; Loss: 7.696491883812939e-07\n",
      "Training Circuit at Epoch 388/500; Loss: 7.470815120980134e-07\n",
      "Training Circuit at Epoch 389/500; Loss: 7.250455104079734e-07\n",
      "Training Circuit at Epoch 390/500; Loss: 7.035323926762871e-07\n",
      "Training Circuit at Epoch 391/500; Loss: 6.825334220028623e-07\n",
      "Training Circuit at Epoch 392/500; Loss: 6.620399168877356e-07\n",
      "Training Circuit at Epoch 393/500; Loss: 6.42043254339697e-07\n",
      "Training Circuit at Epoch 394/500; Loss: 6.225348693211785e-07\n",
      "Training Circuit at Epoch 395/500; Loss: 6.035062608544806e-07\n",
      "Training Circuit at Epoch 396/500; Loss: 5.849489863596347e-07\n",
      "Training Circuit at Epoch 397/500; Loss: 5.668546664283625e-07\n",
      "Training Circuit at Epoch 398/500; Loss: 5.492149920405254e-07\n",
      "Training Circuit at Epoch 399/500; Loss: 5.320217149051842e-07\n",
      "Training Circuit at Epoch 400/500; Loss: 5.152666584518073e-07\n",
      "Training Circuit at Epoch 401/500; Loss: 4.98941712612222e-07\n",
      "Training Circuit at Epoch 402/500; Loss: 4.830388381504847e-07\n",
      "Training Circuit at Epoch 403/500; Loss: 4.675500681061706e-07\n",
      "Training Circuit at Epoch 404/500; Loss: 4.5246750768335176e-07\n",
      "Training Circuit at Epoch 405/500; Loss: 4.377833350277527e-07\n",
      "Training Circuit at Epoch 406/500; Loss: 4.234898053345759e-07\n",
      "Training Circuit at Epoch 407/500; Loss: 4.095792478508997e-07\n",
      "Training Circuit at Epoch 408/500; Loss: 3.9604406865123565e-07\n",
      "Training Circuit at Epoch 409/500; Loss: 3.828767523028631e-07\n",
      "Training Circuit at Epoch 410/500; Loss: 3.7006986264298547e-07\n",
      "Training Circuit at Epoch 411/500; Loss: 3.57616041668507e-07\n",
      "Training Circuit at Epoch 412/500; Loss: 3.455080136438582e-07\n",
      "Training Circuit at Epoch 413/500; Loss: 3.3373858265850487e-07\n",
      "Training Circuit at Epoch 414/500; Loss: 3.223006356245506e-07\n",
      "Training Circuit at Epoch 415/500; Loss: 3.111871418326473e-07\n",
      "Training Circuit at Epoch 416/500; Loss: 3.003911541732407e-07\n",
      "Training Circuit at Epoch 417/500; Loss: 2.8990580813736955e-07\n",
      "Training Circuit at Epoch 418/500; Loss: 2.7972432770084765e-07\n",
      "Training Circuit at Epoch 419/500; Loss: 2.698400178857696e-07\n",
      "Training Circuit at Epoch 420/500; Loss: 2.6024627053367055e-07\n",
      "Training Circuit at Epoch 421/500; Loss: 2.5093656597086067e-07\n",
      "Training Circuit at Epoch 422/500; Loss: 2.419044672352655e-07\n",
      "Training Circuit at Epoch 423/500; Loss: 2.3314362695980861e-07\n",
      "Training Circuit at Epoch 424/500; Loss: 2.246477843748096e-07\n",
      "Training Circuit at Epoch 425/500; Loss: 2.1641076553002847e-07\n",
      "Training Circuit at Epoch 426/500; Loss: 2.0842648496000038e-07\n",
      "Training Circuit at Epoch 427/500; Loss: 2.0068894490687939e-07\n",
      "Training Circuit at Epoch 428/500; Loss: 1.9319223654168383e-07\n",
      "Training Circuit at Epoch 429/500; Loss: 1.8593054007531862e-07\n",
      "Training Circuit at Epoch 430/500; Loss: 1.7889811942950473e-07\n",
      "Training Circuit at Epoch 431/500; Loss: 1.7208933478229937e-07\n",
      "Training Circuit at Epoch 432/500; Loss: 1.6549862724701825e-07\n",
      "Training Circuit at Epoch 433/500; Loss: 1.5912053152877803e-07\n",
      "Training Circuit at Epoch 434/500; Loss: 1.529496684860021e-07\n",
      "Training Circuit at Epoch 435/500; Loss: 1.4698074757291124e-07\n",
      "Training Circuit at Epoch 436/500; Loss: 1.4120856706156815e-07\n",
      "Training Circuit at Epoch 437/500; Loss: 1.3562801193245377e-07\n",
      "Training Circuit at Epoch 438/500; Loss: 1.302340583153594e-07\n",
      "Training Circuit at Epoch 439/500; Loss: 1.2502176593987002e-07\n",
      "Training Circuit at Epoch 440/500; Loss: 1.1998628446363568e-07\n",
      "Training Circuit at Epoch 441/500; Loss: 1.1512284903147929e-07\n",
      "Training Circuit at Epoch 442/500; Loss: 1.1042678194073119e-07\n",
      "Training Circuit at Epoch 443/500; Loss: 1.0589349397349679e-07\n",
      "Training Circuit at Epoch 444/500; Loss: 1.0151847862349683e-07\n",
      "Training Circuit at Epoch 445/500; Loss: 9.72973166479818e-08\n",
      "Training Circuit at Epoch 446/500; Loss: 9.322567384728586e-08\n",
      "Training Circuit at Epoch 447/500; Loss: 8.929930039869305e-08\n",
      "Training Circuit at Epoch 448/500; Loss: 8.551402930212504e-08\n",
      "Training Circuit at Epoch 449/500; Loss: 8.186577937774331e-08\n",
      "Training Circuit at Epoch 450/500; Loss: 7.835055138016855e-08\n",
      "Training Circuit at Epoch 451/500; Loss: 7.496442744336917e-08\n",
      "Training Circuit at Epoch 452/500; Loss: 7.17035723019066e-08\n",
      "Training Circuit at Epoch 453/500; Loss: 6.856423173662307e-08\n",
      "Training Circuit at Epoch 454/500; Loss: 6.554273190850779e-08\n",
      "Training Circuit at Epoch 455/500; Loss: 6.26354769162063e-08\n",
      "Training Circuit at Epoch 456/500; Loss: 5.983895334793488e-08\n",
      "Training Circuit at Epoch 457/500; Loss: 5.714972317605316e-08\n",
      "Training Circuit at Epoch 458/500; Loss: 5.456442642159942e-08\n",
      "Training Circuit at Epoch 459/500; Loss: 5.2079779488956035e-08\n",
      "Training Circuit at Epoch 460/500; Loss: 4.969257605402788e-08\n",
      "Training Circuit at Epoch 461/500; Loss: 4.7399682068238747e-08\n",
      "Training Circuit at Epoch 462/500; Loss: 4.519803997737881e-08\n",
      "Training Circuit at Epoch 463/500; Loss: 4.3084664613779466e-08\n",
      "Training Circuit at Epoch 464/500; Loss: 4.105664364040251e-08\n",
      "Training Circuit at Epoch 465/500; Loss: 3.911113488630491e-08\n",
      "Training Circuit at Epoch 466/500; Loss: 3.724536845606252e-08\n",
      "Training Circuit at Epoch 467/500; Loss: 3.545664251092262e-08\n",
      "Training Circuit at Epoch 468/500; Loss: 3.3742325045160726e-08\n",
      "Training Circuit at Epoch 469/500; Loss: 3.209985210972377e-08\n",
      "Training Circuit at Epoch 470/500; Loss: 3.052672403747181e-08\n",
      "Training Circuit at Epoch 471/500; Loss: 2.902051154940466e-08\n",
      "Training Circuit at Epoch 472/500; Loss: 2.7578845096520865e-08\n",
      "Training Circuit at Epoch 473/500; Loss: 2.619942152115584e-08\n",
      "Training Circuit at Epoch 474/500; Loss: 2.488000250266964e-08\n",
      "Training Circuit at Epoch 475/500; Loss: 2.3618406008729664e-08\n",
      "Training Circuit at Epoch 476/500; Loss: 2.2412516731407095e-08\n",
      "Training Circuit at Epoch 477/500; Loss: 2.1260275318013555e-08\n",
      "Training Circuit at Epoch 478/500; Loss: 2.0159683145060114e-08\n",
      "Training Circuit at Epoch 479/500; Loss: 1.910879776634289e-08\n",
      "Training Circuit at Epoch 480/500; Loss: 1.8105734023166065e-08\n",
      "Training Circuit at Epoch 481/500; Loss: 1.7148663933319597e-08\n",
      "Training Circuit at Epoch 482/500; Loss: 1.6235811917120202e-08\n",
      "Training Circuit at Epoch 483/500; Loss: 1.5365456351723594e-08\n",
      "Training Circuit at Epoch 484/500; Loss: 1.4535930570325206e-08\n",
      "Training Circuit at Epoch 485/500; Loss: 1.3745616200822042e-08\n",
      "Training Circuit at Epoch 486/500; Loss: 1.2992947606704774e-08\n",
      "Training Circuit at Epoch 487/500; Loss: 1.227640655798723e-08\n",
      "Training Circuit at Epoch 488/500; Loss: 1.159452567289776e-08\n",
      "Training Circuit at Epoch 489/500; Loss: 1.0945882533697215e-08\n",
      "Training Circuit at Epoch 490/500; Loss: 1.0329102351214203e-08\n",
      "Training Circuit at Epoch 491/500; Loss: 9.742855633376735e-09\n",
      "Training Circuit at Epoch 492/500; Loss: 9.18585796316762e-09\n",
      "Training Circuit at Epoch 493/500; Loss: 8.656866667955398e-09\n",
      "Training Circuit at Epoch 494/500; Loss: 8.154681485628146e-09\n",
      "Training Circuit at Epoch 495/500; Loss: 7.678144786638086e-09\n",
      "Training Circuit at Epoch 496/500; Loss: 7.226137355154094e-09\n",
      "Training Circuit at Epoch 497/500; Loss: 6.7975816087084695e-09\n",
      "Training Circuit at Epoch 498/500; Loss: 6.391436047081811e-09\n",
      "Training Circuit at Epoch 499/500; Loss: 6.0066986939943945e-09\n",
      "Training Circuit at Epoch 500/500; Loss: 5.6424023231471665e-09\n"
     ]
    }
   ],
   "source": [
    "final_params_2, loss_list_2 = circuitModelTuning(\n",
    "        initial_params=init_params,\n",
    "        model=ToffoliQMLNoiselessAdditionalData,\n",
    "        num_epochs=500,\n",
    "        k=intended_k,\n",
    "        op_pool=pool,\n",
    "        opt_callable=qml.AdamOptimizer,\n",
    "        lr=0.01,\n",
    "        grad_noise_factor=0,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aad997-c96a-4a4d-8b5c-49bf35ee3d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:QuantumResearchPennylane019]",
   "language": "python",
   "name": "conda-env-QuantumResearchPennylane019-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
