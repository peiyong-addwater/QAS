{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f30e184-799d-40cc-a305-8d9322773c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qas.mcts import search, TreeNode, circuitModelTuning\n",
    "from qas.qml_gate_ops import QMLPool\n",
    "from qas.qml_models import ToffoliQMLNoiselessAdditionalData, ToffoliQMLSwapTestNoiselessExtendedData, ToffoliQMLNoiseless\n",
    "import json\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import time\n",
    "from qas.mcts import QMLStateBasicGates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7afc4f15-90ea-4d1c-9f03-1db58dc95c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"0\": {\"U3\": [0]}, \"1\": {\"PlaceHolder\": [0]}, \"2\": {\"U3\": [1]}, \"3\": {\"PlaceHolder\": [1]}, \"4\": {\"U3\": [2]}, \"5\": {\"PlaceHolder\": [2]}, \"6\": {\"CNOT\": [0, 1]}, \"7\": {\"CNOT\": [1, 2]}, \"8\": {\"CNOT\": [0, 2]}}\n"
     ]
    }
   ],
   "source": [
    "model = ToffoliQMLNoiselessAdditionalData\n",
    "state_class = QMLStateBasicGates\n",
    "init_qubit_with_actions = {0, 1, 2}\n",
    "two_qubit_gate = [\"CNOT\"]\n",
    "single_qubit_gate = ['U3','PlaceHolder']\n",
    "gate_limit = {\"CNOT\": 6}\n",
    "control_map = [[0, 1], [1, 2], [0, 2]]\n",
    "pool = QMLPool(3, single_qubit_gate, two_qubit_gate, complete_undirected_graph=False,two_qubit_gate_map=control_map)\n",
    "print(pool)\n",
    "p = 16\n",
    "l = 3\n",
    "c = len(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ee95157-d776-4036-a316-4191c4e1fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "intended_k = [4,7,4,8,4,7,4,8,4,4,2,6,2,6,0,2]\n",
    "init_params = np.random.randn(p, c, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7544e8a-2855-4e0e-8a35-0d3e2cab88db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Circuit at Epoch 1/500; Loss: 0.6825567333038444\n",
      "Training Circuit at Epoch 2/500; Loss: 0.6711173512803572\n",
      "Training Circuit at Epoch 3/500; Loss: 0.6628646178807105\n",
      "Training Circuit at Epoch 4/500; Loss: 0.6559776442139421\n",
      "Training Circuit at Epoch 5/500; Loss: 0.6498800469765369\n",
      "Training Circuit at Epoch 6/500; Loss: 0.6443033797286268\n",
      "Training Circuit at Epoch 7/500; Loss: 0.639097205021427\n",
      "Training Circuit at Epoch 8/500; Loss: 0.6341671383525607\n",
      "Training Circuit at Epoch 9/500; Loss: 0.6294490064218736\n",
      "Training Circuit at Epoch 10/500; Loss: 0.6248962865696056\n",
      "Training Circuit at Epoch 11/500; Loss: 0.6204733637302744\n",
      "Training Circuit at Epoch 12/500; Loss: 0.6161516664895618\n",
      "Training Circuit at Epoch 13/500; Loss: 0.611907354750975\n",
      "Training Circuit at Epoch 14/500; Loss: 0.6077198952741371\n",
      "Training Circuit at Epoch 15/500; Loss: 0.60357116776805\n",
      "Training Circuit at Epoch 16/500; Loss: 0.5994448983383618\n",
      "Training Circuit at Epoch 17/500; Loss: 0.5953262996843305\n",
      "Training Circuit at Epoch 18/500; Loss: 0.5912018438087234\n",
      "Training Circuit at Epoch 19/500; Loss: 0.5870591199073385\n",
      "Training Circuit at Epoch 20/500; Loss: 0.5828867461121566\n",
      "Training Circuit at Epoch 21/500; Loss: 0.5786743135454036\n",
      "Training Circuit at Epoch 22/500; Loss: 0.5744123473769086\n",
      "Training Circuit at Epoch 23/500; Loss: 0.5700922738321736\n",
      "Training Circuit at Epoch 24/500; Loss: 0.5657063852849493\n",
      "Training Circuit at Epoch 25/500; Loss: 0.56124779819434\n",
      "Training Circuit at Epoch 26/500; Loss: 0.5567104009712789\n",
      "Training Circuit at Epoch 27/500; Loss: 0.5520887909890952\n",
      "Training Circuit at Epoch 28/500; Loss: 0.5473782019047075\n",
      "Training Circuit at Epoch 29/500; Loss: 0.5425744242001977\n",
      "Training Circuit at Epoch 30/500; Loss: 0.5376737233377403\n",
      "Training Circuit at Epoch 31/500; Loss: 0.5326727610838867\n",
      "Training Circuit at Epoch 32/500; Loss: 0.5275685263327845\n",
      "Training Circuit at Epoch 33/500; Loss: 0.5223582820572794\n",
      "Training Circuit at Epoch 34/500; Loss: 0.5170395347419283\n",
      "Training Circuit at Epoch 35/500; Loss: 0.5116100317073449\n",
      "Training Circuit at Epoch 36/500; Loss: 0.5060677900756705\n",
      "Training Circuit at Epoch 37/500; Loss: 0.5004111588203246\n",
      "Training Circuit at Epoch 38/500; Loss: 0.4946389126248282\n",
      "Training Circuit at Epoch 39/500; Loss: 0.48875037355929407\n",
      "Training Circuit at Epoch 40/500; Loss: 0.4827455543983943\n",
      "Training Circuit at Epoch 41/500; Loss: 0.4766253162546298\n",
      "Training Circuit at Epoch 42/500; Loss: 0.47039153337160766\n",
      "Training Circuit at Epoch 43/500; Loss: 0.46404725930406443\n",
      "Training Circuit at Epoch 44/500; Loss: 0.4575968907099739\n",
      "Training Circuit at Epoch 45/500; Loss: 0.4510463265926169\n",
      "Training Circuit at Epoch 46/500; Loss: 0.44440312093262857\n",
      "Training Circuit at Epoch 47/500; Loss: 0.4376766244685011\n",
      "Training Circuit at Epoch 48/500; Loss: 0.4308781070081784\n",
      "Training Circuit at Epoch 49/500; Loss: 0.42402084631029424\n",
      "Training Circuit at Epoch 50/500; Loss: 0.4171201653681751\n",
      "Training Circuit at Epoch 51/500; Loss: 0.4101933990061324\n",
      "Training Circuit at Epoch 52/500; Loss: 0.40325977416491776\n",
      "Training Circuit at Epoch 53/500; Loss: 0.3963401955508351\n",
      "Training Circuit at Epoch 54/500; Loss: 0.3894569375021081\n",
      "Training Circuit at Epoch 55/500; Loss: 0.3826332517191323\n",
      "Training Circuit at Epoch 56/500; Loss: 0.3758929074652224\n",
      "Training Circuit at Epoch 57/500; Loss: 0.3692596857909427\n",
      "Training Circuit at Epoch 58/500; Loss: 0.3627568528793609\n",
      "Training Circuit at Epoch 59/500; Loss: 0.3564066402091737\n",
      "Training Circuit at Epoch 60/500; Loss: 0.3502297604987642\n",
      "Training Circuit at Epoch 61/500; Loss: 0.34424498710989093\n",
      "Training Circuit at Epoch 62/500; Loss: 0.3384688194033998\n",
      "Training Circuit at Epoch 63/500; Loss: 0.33291524695777897\n",
      "Training Circuit at Epoch 64/500; Loss: 0.32759561273781523\n",
      "Training Circuit at Epoch 65/500; Loss: 0.32251856212365304\n",
      "Training Circuit at Epoch 66/500; Loss: 0.3176900549208824\n",
      "Training Circuit at Epoch 67/500; Loss: 0.31311341409200066\n",
      "Training Circuit at Epoch 68/500; Loss: 0.3087893888844936\n",
      "Training Circuit at Epoch 69/500; Loss: 0.30471621969364393\n",
      "Training Circuit at Epoch 70/500; Loss: 0.300889704093269\n",
      "Training Circuit at Epoch 71/500; Loss: 0.29730327433835024\n",
      "Training Circuit at Epoch 72/500; Loss: 0.2939481034437177\n",
      "Training Circuit at Epoch 73/500; Loss: 0.2908132582686124\n",
      "Training Circuit at Epoch 74/500; Loss: 0.2878859140236142\n",
      "Training Circuit at Epoch 75/500; Loss: 0.2851516366388418\n",
      "Training Circuit at Epoch 76/500; Loss: 0.2825947295461628\n",
      "Training Circuit at Epoch 77/500; Loss: 0.28019863173975534\n",
      "Training Circuit at Epoch 78/500; Loss: 0.27794634617085057\n",
      "Training Circuit at Epoch 79/500; Loss: 0.275820872681367\n",
      "Training Circuit at Epoch 80/500; Loss: 0.27380561830988837\n",
      "Training Circuit at Epoch 81/500; Loss: 0.2718847599647778\n",
      "Training Circuit at Epoch 82/500; Loss: 0.2700435397451022\n",
      "Training Circuit at Epoch 83/500; Loss: 0.26826848072622234\n",
      "Training Circuit at Epoch 84/500; Loss: 0.26654751957413725\n",
      "Training Circuit at Epoch 85/500; Loss: 0.2648700605366535\n",
      "Training Circuit at Epoch 86/500; Loss: 0.263226961943678\n",
      "Training Circuit at Epoch 87/500; Loss: 0.26161047045430363\n",
      "Training Circuit at Epoch 88/500; Loss: 0.2600141195286181\n",
      "Training Circuit at Epoch 89/500; Loss: 0.2584326071442413\n",
      "Training Circuit at Epoch 90/500; Loss: 0.2568616643251601\n",
      "Training Circuit at Epoch 91/500; Loss: 0.25529792171809607\n",
      "Training Circuit at Epoch 92/500; Loss: 0.25373877750199825\n",
      "Training Circuit at Epoch 93/500; Loss: 0.25218226739473093\n",
      "Training Circuit at Epoch 94/500; Loss: 0.2506269369105647\n",
      "Training Circuit at Epoch 95/500; Loss: 0.2490717170789819\n",
      "Training Circuit at Epoch 96/500; Loss: 0.24751580670811713\n",
      "Training Circuit at Epoch 97/500; Loss: 0.24595856587089704\n",
      "Training Circuit at Epoch 98/500; Loss: 0.24439942571987883\n",
      "Training Circuit at Epoch 99/500; Loss: 0.24283781864666454\n",
      "Training Circuit at Epoch 100/500; Loss: 0.2412731304684378\n",
      "Training Circuit at Epoch 101/500; Loss: 0.23970467348878877\n",
      "Training Circuit at Epoch 102/500; Loss: 0.238131676834885\n",
      "Training Circuit at Epoch 103/500; Loss: 0.2365532891304054\n",
      "Training Circuit at Epoch 104/500; Loss: 0.2349685886288181\n",
      "Training Circuit at Epoch 105/500; Loss: 0.2333765972453723\n",
      "Training Circuit at Epoch 106/500; Loss: 0.23177629697108093\n",
      "Training Circuit at Epoch 107/500; Loss: 0.23016664925777852\n",
      "Training Circuit at Epoch 108/500; Loss: 0.22854661952503386\n",
      "Training Circuit at Epoch 109/500; Loss: 0.226915209575262\n",
      "Training Circuit at Epoch 110/500; Loss: 0.22527150031644128\n",
      "Training Circuit at Epoch 111/500; Loss: 0.22361470594869404\n",
      "Training Circuit at Epoch 112/500; Loss: 0.2219442390208738\n",
      "Training Circuit at Epoch 113/500; Loss: 0.22025978393661472\n",
      "Training Circuit at Epoch 114/500; Loss: 0.21856137499359174\n",
      "Training Circuit at Epoch 115/500; Loss: 0.2168494741713658\n",
      "Training Circuit at Epoch 116/500; Loss: 0.21512504376379937\n",
      "Training Circuit at Epoch 117/500; Loss: 0.2133896095086557\n",
      "Training Circuit at Epoch 118/500; Loss: 0.21164531086157223\n",
      "Training Circuit at Epoch 119/500; Loss: 0.20989493616955013\n",
      "Training Circuit at Epoch 120/500; Loss: 0.2081419414145932\n",
      "Training Circuit at Epoch 121/500; Loss: 0.20639045173366766\n",
      "Training Circuit at Epoch 122/500; Loss: 0.20464524506495751\n",
      "Training Circuit at Epoch 123/500; Loss: 0.2029117171784277\n",
      "Training Circuit at Epoch 124/500; Loss: 0.20119582727021412\n",
      "Training Circuit at Epoch 125/500; Loss: 0.1995040234673442\n",
      "Training Circuit at Epoch 126/500; Loss: 0.197843148115188\n",
      "Training Circuit at Epoch 127/500; Loss: 0.19622032355601016\n",
      "Training Circuit at Epoch 128/500; Loss: 0.19464282007355893\n",
      "Training Circuit at Epoch 129/500; Loss: 0.19311790855764666\n",
      "Training Circuit at Epoch 130/500; Loss: 0.19165270107993182\n",
      "Training Circuit at Epoch 131/500; Loss: 0.19025398294195217\n",
      "Training Circuit at Epoch 132/500; Loss: 0.18892803996037133\n",
      "Training Circuit at Epoch 133/500; Loss: 0.18768048496220002\n",
      "Training Circuit at Epoch 134/500; Loss: 0.18651608783158458\n",
      "Training Circuit at Epoch 135/500; Loss: 0.18543861405625084\n",
      "Training Circuit at Epoch 136/500; Loss: 0.18445067753097066\n",
      "Training Circuit at Epoch 137/500; Loss: 0.1835536142462768\n",
      "Training Circuit at Epoch 138/500; Loss: 0.1827473842057844\n",
      "Training Circuit at Epoch 139/500; Loss: 0.18203050922381714\n",
      "Training Circuit at Epoch 140/500; Loss: 0.18140005391779557\n",
      "Training Circuit at Epoch 141/500; Loss: 0.18085165604581366\n",
      "Training Circuit at Epoch 142/500; Loss: 0.1803796102660441\n",
      "Training Circuit at Epoch 143/500; Loss: 0.1799770064534406\n",
      "Training Circuit at Epoch 144/500; Loss: 0.1796359200785861\n",
      "Training Circuit at Epoch 145/500; Loss: 0.17934764813326587\n",
      "Training Circuit at Epoch 146/500; Loss: 0.179102980068914\n",
      "Training Circuit at Epoch 147/500; Loss: 0.17889248963804172\n",
      "Training Circuit at Epoch 148/500; Loss: 0.1787068308395069\n",
      "Training Circuit at Epoch 149/500; Loss: 0.17853701976776326\n",
      "Training Circuit at Epoch 150/500; Loss: 0.1783746843613535\n",
      "Training Circuit at Epoch 151/500; Loss: 0.1782122659899702\n",
      "Training Circuit at Epoch 152/500; Loss: 0.17804316044785373\n",
      "Training Circuit at Epoch 153/500; Loss: 0.17786179090867305\n",
      "Training Circuit at Epoch 154/500; Loss: 0.17766361116481977\n",
      "Training Circuit at Epoch 155/500; Loss: 0.17744504327072785\n",
      "Training Circuit at Epoch 156/500; Loss: 0.17720335875545046\n",
      "Training Circuit at Epoch 157/500; Loss: 0.17693651622229933\n",
      "Training Circuit at Epoch 158/500; Loss: 0.17664297004266272\n",
      "Training Circuit at Epoch 159/500; Loss: 0.1763214649346735\n",
      "Training Circuit at Epoch 160/500; Loss: 0.17597082975122635\n",
      "Training Circuit at Epoch 161/500; Loss: 0.17558978124615043\n",
      "Training Circuit at Epoch 162/500; Loss: 0.17517674548803774\n",
      "Training Circuit at Epoch 163/500; Loss: 0.1747297014711724\n",
      "Training Circuit at Epoch 164/500; Loss: 0.1742460487539106\n",
      "Training Circuit at Epoch 165/500; Loss: 0.1737224989150713\n",
      "Training Circuit at Epoch 166/500; Loss: 0.1731549893841069\n",
      "Training Circuit at Epoch 167/500; Loss: 0.1725386177604864\n",
      "Training Circuit at Epoch 168/500; Loss: 0.17186759497913595\n",
      "Training Circuit at Epoch 169/500; Loss: 0.17113521642920648\n",
      "Training Circuit at Epoch 170/500; Loss: 0.1703338511999858\n",
      "Training Circuit at Epoch 171/500; Loss: 0.16945495082831186\n",
      "Training Circuit at Epoch 172/500; Loss: 0.16848908010279584\n",
      "Training Circuit at Epoch 173/500; Loss: 0.16742597352205635\n",
      "Training Circuit at Epoch 174/500; Loss: 0.1662546218178791\n",
      "Training Circuit at Epoch 175/500; Loss: 0.16496339346983768\n",
      "Training Circuit at Epoch 176/500; Loss: 0.16354019629139238\n",
      "Training Circuit at Epoch 177/500; Loss: 0.1619726838867589\n",
      "Training Circuit at Epoch 178/500; Loss: 0.1602485109756263\n",
      "Training Circuit at Epoch 179/500; Loss: 0.15835564015836423\n",
      "Training Circuit at Epoch 180/500; Loss: 0.1562827005470705\n",
      "Training Circuit at Epoch 181/500; Loss: 0.15401939574058698\n",
      "Training Circuit at Epoch 182/500; Loss: 0.1515569548516501\n",
      "Training Circuit at Epoch 183/500; Loss: 0.14888861576608325\n",
      "Training Circuit at Epoch 184/500; Loss: 0.14601012471349628\n",
      "Training Circuit at Epoch 185/500; Loss: 0.1429202308911378\n",
      "Training Circuit at Epoch 186/500; Loss: 0.13962114980486862\n",
      "Training Circuit at Epoch 187/500; Loss: 0.13611896481698638\n",
      "Training Circuit at Epoch 188/500; Loss: 0.13242393385252016\n",
      "Training Circuit at Epoch 189/500; Loss: 0.12855066803203785\n",
      "Training Circuit at Epoch 190/500; Loss: 0.12451815173845926\n",
      "Training Circuit at Epoch 191/500; Loss: 0.12034957956397196\n",
      "Training Circuit at Epoch 192/500; Loss: 0.1160719946006602\n",
      "Training Circuit at Epoch 193/500; Loss: 0.11171572409563535\n",
      "Training Circuit at Epoch 194/500; Loss: 0.10731362172096115\n",
      "Training Circuit at Epoch 195/500; Loss: 0.1029001396002589\n",
      "Training Circuit at Epoch 196/500; Loss: 0.09851026682413722\n",
      "Training Circuit at Epoch 197/500; Loss: 0.09417838361620534\n",
      "Training Circuit at Epoch 198/500; Loss: 0.08993709069177735\n",
      "Training Circuit at Epoch 199/500; Loss: 0.08581608058945656\n",
      "Training Circuit at Epoch 200/500; Loss: 0.08184112061236404\n",
      "Training Circuit at Epoch 201/500; Loss: 0.0780332144721374\n",
      "Training Circuit at Epoch 202/500; Loss: 0.07440800134334646\n",
      "Training Circuit at Epoch 203/500; Loss: 0.07097543693152508\n",
      "Training Circuit at Epoch 204/500; Loss: 0.06773978177772977\n",
      "Training Circuit at Epoch 205/500; Loss: 0.06469989818828092\n",
      "Training Circuit at Epoch 206/500; Loss: 0.06184983062024785\n",
      "Training Circuit at Epoch 207/500; Loss: 0.0591796181468871\n",
      "Training Circuit at Epoch 208/500; Loss: 0.05667626586457786\n",
      "Training Circuit at Epoch 209/500; Loss: 0.05432478880369873\n",
      "Training Circuit at Epoch 210/500; Loss: 0.052109239772311744\n",
      "Training Circuit at Epoch 211/500; Loss: 0.050013642096364275\n",
      "Training Circuit at Epoch 212/500; Loss: 0.04802276741537348\n",
      "Training Circuit at Epoch 213/500; Loss: 0.04612272343145074\n",
      "Training Circuit at Epoch 214/500; Loss: 0.04430134176405498\n",
      "Training Circuit at Epoch 215/500; Loss: 0.04254837749292362\n",
      "Training Circuit at Epoch 216/500; Loss: 0.04085554706983152\n",
      "Training Circuit at Epoch 217/500; Loss: 0.03921643949736242\n",
      "Training Circuit at Epoch 218/500; Loss: 0.03762633780463587\n",
      "Training Circuit at Epoch 219/500; Loss: 0.03608198536223339\n",
      "Training Circuit at Epoch 220/500; Loss: 0.03458132618862908\n",
      "Training Circuit at Epoch 221/500; Loss: 0.03312324176183612\n",
      "Training Circuit at Epoch 222/500; Loss: 0.03170730026231017\n",
      "Training Circuit at Epoch 223/500; Loss: 0.0303335284627384\n",
      "Training Circuit at Epoch 224/500; Loss: 0.029002212079449863\n",
      "Training Circuit at Epoch 225/500; Loss: 0.02771372742210443\n",
      "Training Circuit at Epoch 226/500; Loss: 0.026468405398906936\n",
      "Training Circuit at Epoch 227/500; Loss: 0.025266427863414265\n",
      "Training Circuit at Epoch 228/500; Loss: 0.02410775542777044\n",
      "Training Circuit at Epoch 229/500; Loss: 0.022992084945769764\n",
      "Training Circuit at Epoch 230/500; Loss: 0.021918833855923858\n",
      "Training Circuit at Epoch 231/500; Loss: 0.020887147570769704\n",
      "Training Circuit at Epoch 232/500; Loss: 0.01989592529229267\n",
      "Training Circuit at Epoch 233/500; Loss: 0.018943859258998552\n",
      "Training Circuit at Epoch 234/500; Loss: 0.018029482619808967\n",
      "Training Circuit at Epoch 235/500; Loss: 0.01715122177925632\n",
      "Training Circuit at Epoch 236/500; Loss: 0.016307449886153402\n",
      "Training Circuit at Epoch 237/500; Loss: 0.015496538872565746\n",
      "Training Circuit at Epoch 238/500; Loss: 0.01471690794037217\n",
      "Training Circuit at Epoch 239/500; Loss: 0.013967066615580004\n",
      "Training Circuit at Epoch 240/500; Loss: 0.013245650548404098\n",
      "Training Circuit at Epoch 241/500; Loss: 0.012551448336277193\n",
      "Training Circuit at Epoch 242/500; Loss: 0.011883417987239908\n",
      "Training Circuit at Epoch 243/500; Loss: 0.011240692285154563\n",
      "Training Circuit at Epoch 244/500; Loss: 0.0106225731737154\n",
      "Training Circuit at Epoch 245/500; Loss: 0.010028516176899371\n",
      "Training Circuit at Epoch 246/500; Loss: 0.009458106648810305\n",
      "Training Circuit at Epoch 247/500; Loss: 0.008911030162531697\n",
      "Training Circuit at Epoch 248/500; Loss: 0.008387039557279596\n",
      "Training Circuit at Epoch 249/500; Loss: 0.007885921118665706\n",
      "Training Circuit at Epoch 250/500; Loss: 0.007407462163625977\n",
      "Training Circuit at Epoch 251/500; Loss: 0.0069514220024873286\n",
      "Training Circuit at Epoch 252/500; Loss: 0.006517507876271034\n",
      "Training Circuit at Epoch 253/500; Loss: 0.006105357025603997\n",
      "Training Circuit at Epoch 254/500; Loss: 0.005714525547039995\n",
      "Training Circuit at Epoch 255/500; Loss: 0.005344484150552886\n",
      "Training Circuit at Epoch 256/500; Loss: 0.004994620395173954\n",
      "Training Circuit at Epoch 257/500; Loss: 0.004664246522261162\n",
      "Training Circuit at Epoch 258/500; Loss: 0.004352611688209884\n",
      "Training Circuit at Epoch 259/500; Loss: 0.004058917236357873\n",
      "Training Circuit at Epoch 260/500; Loss: 0.003782333622486256\n",
      "Training Circuit at Epoch 261/500; Loss: 0.0035220176855939034\n",
      "Training Circuit at Epoch 262/500; Loss: 0.0032771290977932077\n",
      "Training Circuit at Epoch 263/500; Loss: 0.0030468450079338405\n",
      "Training Circuit at Epoch 264/500; Loss: 0.00283037211064463\n",
      "Training Circuit at Epoch 265/500; Loss: 0.0026269556332843003\n",
      "Training Circuit at Epoch 266/500; Loss: 0.0024358850293505485\n",
      "Training Circuit at Epoch 267/500; Loss: 0.0022564964690491296\n",
      "Training Circuit at Epoch 268/500; Loss: 0.002088172487199502\n",
      "Training Circuit at Epoch 269/500; Loss: 0.0019303393481580056\n",
      "Training Circuit at Epoch 270/500; Loss: 0.0017824627922906622\n",
      "Training Circuit at Epoch 271/500; Loss: 0.001644042840733606\n",
      "Training Circuit at Epoch 272/500; Loss: 0.0015146082796950733\n",
      "Training Circuit at Epoch 273/500; Loss: 0.0013937113513958765\n",
      "Training Circuit at Epoch 274/500; Loss: 0.0012809230650103753\n",
      "Training Circuit at Epoch 275/500; Loss: 0.001175829417716323\n",
      "Training Circuit at Epoch 276/500; Loss: 0.0010780286870972766\n",
      "Training Circuit at Epoch 277/500; Loss: 0.0009871298245275328\n",
      "Training Circuit at Epoch 278/500; Loss: 0.0009027518545345892\n",
      "Training Circuit at Epoch 279/500; Loss: 0.0008245240852655655\n",
      "Training Circuit at Epoch 280/500; Loss: 0.0007520868756939469\n",
      "Training Circuit at Epoch 281/500; Loss: 0.0006850926914411248\n",
      "Training Circuit at Epoch 282/500; Loss: 0.0006232072076542972\n",
      "Training Circuit at Epoch 283/500; Loss: 0.0005661102704389576\n",
      "Training Circuit at Epoch 284/500; Loss: 0.0005134965906194999\n",
      "Training Circuit at Epoch 285/500; Loss: 0.00046507610209556294\n",
      "Training Circuit at Epoch 286/500; Loss: 0.0004205739670630759\n",
      "Training Circuit at Epoch 287/500; Loss: 0.0003797302514096934\n",
      "Training Circuit at Epoch 288/500; Loss: 0.00034229932572127364\n",
      "Training Circuit at Epoch 289/500; Loss: 0.0003080490699327587\n",
      "Training Circuit at Epoch 290/500; Loss: 0.00027675997129428254\n",
      "Training Circuit at Epoch 291/500; Loss: 0.00024822420416825697\n",
      "Training Circuit at Epoch 292/500; Loss: 0.0002222447671049732\n",
      "Training Circuit at Epoch 293/500; Loss: 0.00019863473210779414\n",
      "Training Circuit at Epoch 294/500; Loss: 0.00017721663819603162\n",
      "Training Circuit at Epoch 295/500; Loss: 0.00015782204027581237\n",
      "Training Circuit at Epoch 296/500; Loss: 0.00014029120709557752\n",
      "Training Circuit at Epoch 297/500; Loss: 0.00012447294867212744\n",
      "Training Circuit at Epoch 298/500; Loss: 0.00011022454286557792\n",
      "Training Circuit at Epoch 299/500; Loss: 9.741172298238787e-05\n",
      "Training Circuit at Epoch 300/500; Loss: 8.590868473146163e-05\n",
      "Training Circuit at Epoch 301/500; Loss: 7.559807286239284e-05\n",
      "Training Circuit at Epoch 302/500; Loss: 6.637091526673355e-05\n",
      "Training Circuit at Epoch 303/500; Loss: 5.812648370995266e-05\n",
      "Training Circuit at Epoch 304/500; Loss: 5.077207263037842e-05\n",
      "Training Circuit at Epoch 305/500; Loss: 4.422269747894614e-05\n",
      "Training Circuit at Epoch 306/500; Loss: 3.8400720804188104e-05\n",
      "Training Circuit at Epoch 307/500; Loss: 3.3235418067989464e-05\n",
      "Training Circuit at Epoch 308/500; Loss: 2.8662497346232385e-05\n",
      "Training Circuit at Epoch 309/500; Loss: 2.4623588738781343e-05\n",
      "Training Circuit at Epoch 310/500; Loss: 2.106572073046209e-05\n",
      "Training Circuit at Epoch 311/500; Loss: 1.7940801156024477e-05\n",
      "Training Circuit at Epoch 312/500; Loss: 1.5205119199057648e-05\n",
      "Training Circuit at Epoch 313/500; Loss: 1.2818882103138307e-05\n",
      "Training Circuit at Epoch 314/500; Loss: 1.0745796488964565e-05\n",
      "Training Circuit at Epoch 315/500; Loss: 8.952700308872963e-06\n",
      "Training Circuit at Epoch 316/500; Loss: 7.40924792030917e-06\n",
      "Training Circuit at Epoch 317/500; Loss: 6.087647655750317e-06\n",
      "Training Circuit at Epoch 318/500; Loss: 4.962448304390854e-06\n",
      "Training Circuit at Epoch 319/500; Loss: 4.01036823227674e-06\n",
      "Training Circuit at Epoch 320/500; Loss: 3.210158714961331e-06\n",
      "Training Circuit at Epoch 321/500; Loss: 2.5424919930516765e-06\n",
      "Training Circuit at Epoch 322/500; Loss: 1.989864675588926e-06\n",
      "Training Circuit at Epoch 323/500; Loss: 1.536508344557319e-06\n",
      "Training Circuit at Epoch 324/500; Loss: 1.168300980403103e-06\n",
      "Training Circuit at Epoch 325/500; Loss: 8.726747103837695e-07\n",
      "Training Circuit at Epoch 326/500; Loss: 6.385172408585049e-07\n",
      "Training Circuit at Epoch 327/500; Loss: 4.560660928909499e-07\n",
      "Training Circuit at Epoch 328/500; Loss: 3.167964635064635e-07\n",
      "Training Circuit at Epoch 329/500; Loss: 2.133050563957184e-07\n",
      "Training Circuit at Epoch 330/500; Loss: 1.3919325891897927e-07\n",
      "Training Circuit at Epoch 331/500; Loss: 8.895344461024024e-08\n",
      "Training Circuit at Epoch 332/500; Loss: 5.7861805458081506e-08\n",
      "Training Circuit at Epoch 333/500; Loss: 4.188032864949065e-08\n",
      "Training Circuit at Epoch 334/500; Loss: 3.756949773503493e-08\n",
      "Training Circuit at Epoch 335/500; Loss: 4.2012331613605625e-08\n",
      "Training Circuit at Epoch 336/500; Loss: 5.274953196465759e-08\n",
      "Training Circuit at Epoch 337/500; Loss: 6.77247699032435e-08\n",
      "Training Circuit at Epoch 338/500; Loss: 8.523856998010615e-08\n",
      "Training Circuit at Epoch 339/500; Loss: 1.0390881033384147e-07\n",
      "Training Circuit at Epoch 340/500; Loss: 1.2263578685889343e-07\n",
      "Training Circuit at Epoch 341/500; Loss: 1.4057004449341548e-07\n",
      "Training Circuit at Epoch 342/500; Loss: 1.5708166156702674e-07\n",
      "Training Circuit at Epoch 343/500; Loss: 1.7173031774397884e-07\n",
      "Training Circuit at Epoch 344/500; Loss: 1.842360366488549e-07\n",
      "Training Circuit at Epoch 345/500; Loss: 1.944508930540323e-07\n",
      "Training Circuit at Epoch 346/500; Loss: 2.0233223874122075e-07\n",
      "Training Circuit at Epoch 347/500; Loss: 2.0791813870602027e-07\n",
      "Training Circuit at Epoch 348/500; Loss: 2.1130564764604287e-07\n",
      "Training Circuit at Epoch 349/500; Loss: 2.1263242033775498e-07\n",
      "Training Circuit at Epoch 350/500; Loss: 2.1206190070621744e-07\n",
      "Training Circuit at Epoch 351/500; Loss: 2.0977197945359904e-07\n",
      "Training Circuit at Epoch 352/500; Loss: 2.0594681893193467e-07\n",
      "Training Circuit at Epoch 353/500; Loss: 2.0077130580276048e-07\n",
      "Training Circuit at Epoch 354/500; Loss: 1.9442757626109142e-07\n",
      "Training Circuit at Epoch 355/500; Loss: 1.8709300031449771e-07\n",
      "Training Circuit at Epoch 356/500; Loss: 1.789390862150242e-07\n",
      "Training Circuit at Epoch 357/500; Loss: 1.7013079633976247e-07\n",
      "Training Circuit at Epoch 358/500; Loss: 1.6082591913768596e-07\n",
      "Training Circuit at Epoch 359/500; Loss: 1.5117424523314327e-07\n",
      "Training Circuit at Epoch 360/500; Loss: 1.41316515711587e-07\n",
      "Training Circuit at Epoch 361/500; Loss: 1.3138319487904226e-07\n",
      "Training Circuit at Epoch 362/500; Loss: 1.2149320549603715e-07\n",
      "Training Circuit at Epoch 363/500; Loss: 1.1175280445474556e-07\n",
      "Training Circuit at Epoch 364/500; Loss: 1.0225470792324387e-07\n",
      "Training Circuit at Epoch 365/500; Loss: 9.307759107901603e-08\n",
      "Training Circuit at Epoch 366/500; Loss: 8.428599518328639e-08\n",
      "Training Circuit at Epoch 367/500; Loss: 7.593066719824293e-08\n",
      "Training Circuit at Epoch 368/500; Loss: 6.804928021075796e-08\n",
      "Training Circuit at Epoch 369/500; Loss: 6.066746971455927e-08\n",
      "Training Circuit at Epoch 370/500; Loss: 5.380007150890265e-08\n",
      "Training Circuit at Epoch 371/500; Loss: 4.745248705084748e-08\n",
      "Training Circuit at Epoch 372/500; Loss: 4.1622077118219636e-08\n",
      "Training Circuit at Epoch 373/500; Loss: 3.6299517391924496e-08\n",
      "Training Circuit at Epoch 374/500; Loss: 3.147006832904253e-08\n",
      "Training Circuit at Epoch 375/500; Loss: 2.7114703482489233e-08\n",
      "Training Circuit at Epoch 376/500; Loss: 2.32110970443955e-08\n",
      "Training Circuit at Epoch 377/500; Loss: 1.973445651337613e-08\n",
      "Training Circuit at Epoch 378/500; Loss: 1.665822091378999e-08\n",
      "Training Circuit at Epoch 379/500; Loss: 1.3954651212344515e-08\n",
      "Training Circuit at Epoch 380/500; Loss: 1.159533091765752e-08\n",
      "Training Circuit at Epoch 381/500; Loss: 9.551602286883565e-09\n",
      "Training Circuit at Epoch 382/500; Loss: 7.794951351058899e-09\n",
      "Training Circuit at Epoch 383/500; Loss: 6.297367849406044e-09\n",
      "Training Circuit at Epoch 384/500; Loss: 5.0316695254792876e-09\n",
      "Training Circuit at Epoch 385/500; Loss: 3.971815987213745e-09\n",
      "Training Circuit at Epoch 386/500; Loss: 3.0931788241872482e-09\n",
      "Training Circuit at Epoch 387/500; Loss: 2.372770424585724e-09\n",
      "Training Circuit at Epoch 388/500; Loss: 1.7894099535453734e-09\n",
      "Training Circuit at Epoch 389/500; Loss: 1.3238320439867834e-09\n",
      "Training Circuit at Epoch 390/500; Loss: 9.587121096998885e-10\n",
      "Training Circuit at Epoch 391/500; Loss: 6.786371464784224e-10\n",
      "Training Circuit at Epoch 392/500; Loss: 4.700079214714492e-10\n",
      "Training Circuit at Epoch 393/500; Loss: 3.208933119225321e-10\n",
      "Training Circuit at Epoch 394/500; Loss: 2.2085788753400948e-10\n",
      "Training Circuit at Epoch 395/500; Loss: 1.6077783548951174e-10\n",
      "Training Circuit at Epoch 396/500; Loss: 1.32657440587991e-10\n",
      "Training Circuit at Epoch 397/500; Loss: 1.2947931615769903e-10\n",
      "Training Circuit at Epoch 398/500; Loss: 1.450793929436145e-10\n",
      "Training Circuit at Epoch 399/500; Loss: 1.7405743513165817e-10\n",
      "Training Circuit at Epoch 400/500; Loss: 2.1172008590752966e-10\n",
      "Training Circuit at Epoch 401/500; Loss: 2.540536669926041e-10\n",
      "Training Circuit at Epoch 402/500; Loss: 2.9770030884890275e-10\n",
      "Training Circuit at Epoch 403/500; Loss: 3.399450720920072e-10\n",
      "Training Circuit at Epoch 404/500; Loss: 3.786887470269562e-10\n",
      "Training Circuit at Epoch 405/500; Loss: 4.124095509538961e-10\n",
      "Training Circuit at Epoch 406/500; Loss: 4.4011194688664546e-10\n",
      "Training Circuit at Epoch 407/500; Loss: 4.6125381292227985e-10\n",
      "Training Circuit at Epoch 408/500; Loss: 4.756764981905803e-10\n",
      "Training Circuit at Epoch 409/500; Loss: 4.835213340825817e-10\n",
      "Training Circuit at Epoch 410/500; Loss: 4.851486989920772e-10\n",
      "Training Circuit at Epoch 411/500; Loss: 4.81071071867234e-10\n",
      "Training Circuit at Epoch 412/500; Loss: 4.718926360780529e-10\n",
      "Training Circuit at Epoch 413/500; Loss: 4.5826331618314953e-10\n",
      "Training Circuit at Epoch 414/500; Loss: 4.408493570196015e-10\n",
      "Training Circuit at Epoch 415/500; Loss: 4.203070114172647e-10\n",
      "Training Circuit at Epoch 416/500; Loss: 3.972739914814838e-10\n",
      "Training Circuit at Epoch 417/500; Loss: 3.7235836636284603e-10\n",
      "Training Circuit at Epoch 418/500; Loss: 3.461380071456688e-10\n",
      "Training Circuit at Epoch 419/500; Loss: 3.191475972386115e-10\n",
      "Training Circuit at Epoch 420/500; Loss: 2.9187974259770044e-10\n",
      "Training Circuit at Epoch 421/500; Loss: 2.6477864345508806e-10\n",
      "Training Circuit at Epoch 422/500; Loss: 2.382354313823498e-10\n",
      "Training Circuit at Epoch 423/500; Loss: 2.125848386214102e-10\n",
      "Training Circuit at Epoch 424/500; Loss: 1.8810120128165408e-10\n",
      "Training Circuit at Epoch 425/500; Loss: 1.6500023569676614e-10\n",
      "Training Circuit at Epoch 426/500; Loss: 1.4344048171466284e-10\n",
      "Training Circuit at Epoch 427/500; Loss: 1.2352951994643036e-10\n",
      "Training Circuit at Epoch 428/500; Loss: 1.0532641425697875e-10\n",
      "Training Circuit at Epoch 429/500; Loss: 8.884981639312173e-11\n",
      "Training Circuit at Epoch 430/500; Loss: 7.408451629942192e-11\n",
      "Training Circuit at Epoch 431/500; Loss: 6.098899163475835e-11\n",
      "Training Circuit at Epoch 432/500; Loss: 4.9498849463702754e-11\n",
      "Training Circuit at Epoch 433/500; Loss: 3.95365962191363e-11\n",
      "Training Circuit at Epoch 434/500; Loss: 3.100764089936092e-11\n",
      "Training Circuit at Epoch 435/500; Loss: 2.381173036525297e-11\n",
      "Training Circuit at Epoch 436/500; Loss: 1.783972969349179e-11\n",
      "Training Circuit at Epoch 437/500; Loss: 1.2981837826941955e-11\n",
      "Training Circuit at Epoch 438/500; Loss: 9.120593169598123e-12\n",
      "Training Circuit at Epoch 439/500; Loss: 6.140199459991891e-12\n",
      "Training Circuit at Epoch 440/500; Loss: 3.9253045258647035e-12\n",
      "Training Circuit at Epoch 441/500; Loss: 2.362332551797408e-12\n",
      "Training Circuit at Epoch 442/500; Loss: 1.3435919044013644e-12\n",
      "Training Circuit at Epoch 443/500; Loss: 7.680522884356833e-13\n",
      "Training Circuit at Epoch 444/500; Loss: 5.39124300757976e-13\n",
      "Training Circuit at Epoch 445/500; Loss: 5.745404152435185e-13\n",
      "Training Circuit at Epoch 446/500; Loss: 7.991385331251877e-13\n",
      "Training Circuit at Epoch 447/500; Loss: 1.149524919696887e-12\n",
      "Training Circuit at Epoch 448/500; Loss: 1.5732970481963093e-12\n",
      "Training Circuit at Epoch 449/500; Loss: 2.0266011091507607e-12\n",
      "Training Circuit at Epoch 450/500; Loss: 2.4766855233337992e-12\n",
      "Training Circuit at Epoch 451/500; Loss: 2.8985702726913587e-12\n",
      "Training Circuit at Epoch 452/500; Loss: 3.270272941335861e-12\n",
      "Training Circuit at Epoch 453/500; Loss: 3.5816904997432175e-12\n",
      "Training Circuit at Epoch 454/500; Loss: 3.823608096809039e-12\n",
      "Training Circuit at Epoch 455/500; Loss: 3.993916308786538e-12\n",
      "Training Circuit at Epoch 456/500; Loss: 4.090616734231389e-12\n",
      "Training Circuit at Epoch 457/500; Loss: 4.1173731091248555e-12\n",
      "Training Circuit at Epoch 458/500; Loss: 4.08006961549745e-12\n",
      "Training Circuit at Epoch 459/500; Loss: 3.984590435379687e-12\n",
      "Training Circuit at Epoch 460/500; Loss: 3.841038598295654e-12\n",
      "Training Circuit at Epoch 461/500; Loss: 3.656297486998028e-12\n",
      "Training Circuit at Epoch 462/500; Loss: 3.4406921756158226e-12\n",
      "Training Circuit at Epoch 463/500; Loss: 3.2016611584140264e-12\n",
      "Training Circuit at Epoch 464/500; Loss: 2.9469759965650155e-12\n",
      "Training Circuit at Epoch 465/500; Loss: 2.6840751843337785e-12\n",
      "Training Circuit at Epoch 466/500; Loss: 2.4195090375656036e-12\n",
      "Training Circuit at Epoch 467/500; Loss: 2.156497203031904e-12\n",
      "Training Circuit at Epoch 468/500; Loss: 1.900923862763193e-12\n",
      "Training Circuit at Epoch 469/500; Loss: 1.655675596623496e-12\n",
      "Training Circuit at Epoch 470/500; Loss: 1.4249712521063884e-12\n",
      "Training Circuit at Epoch 471/500; Loss: 1.2084777623044829e-12\n",
      "Training Circuit at Epoch 472/500; Loss: 1.010858063921205e-12\n",
      "Training Circuit at Epoch 473/500; Loss: 8.324452238639424e-13\n",
      "Training Circuit at Epoch 474/500; Loss: 6.726841306203823e-13\n",
      "Training Circuit at Epoch 475/500; Loss: 5.347944309619379e-13\n",
      "Training Circuit at Epoch 476/500; Loss: 4.155564781171961e-13\n",
      "Training Circuit at Epoch 477/500; Loss: 3.1585845050585704e-13\n",
      "Training Circuit at Epoch 478/500; Loss: 2.333688797762079e-13\n",
      "Training Circuit at Epoch 479/500; Loss: 1.674216321134736e-13\n",
      "Training Circuit at Epoch 480/500; Loss: 1.162403506782539e-13\n",
      "Training Circuit at Epoch 481/500; Loss: 7.738254481637341e-14\n",
      "Training Circuit at Epoch 482/500; Loss: 4.9960036108132044e-14\n",
      "Training Circuit at Epoch 483/500; Loss: 3.11972669919669e-14\n",
      "Training Circuit at Epoch 484/500; Loss: 2.042810365310288e-14\n",
      "Training Circuit at Epoch 485/500; Loss: 1.5432100042289676e-14\n",
      "Training Circuit at Epoch 486/500; Loss: 1.4765966227514582e-14\n",
      "Training Circuit at Epoch 487/500; Loss: 1.765254609153999e-14\n",
      "Training Circuit at Epoch 488/500; Loss: 2.275957200481571e-14\n",
      "Training Circuit at Epoch 489/500; Loss: 2.964295475749168e-14\n",
      "Training Circuit at Epoch 490/500; Loss: 3.697042672001771e-14\n",
      "Training Circuit at Epoch 491/500; Loss: 4.374278717023117e-14\n",
      "Training Circuit at Epoch 492/500; Loss: 5.040412531798211e-14\n",
      "Training Circuit at Epoch 493/500; Loss: 5.706546346573305e-14\n",
      "Training Circuit at Epoch 494/500; Loss: 6.161737786669619e-14\n",
      "Training Circuit at Epoch 495/500; Loss: 6.583622536027178e-14\n",
      "Training Circuit at Epoch 496/500; Loss: 6.783462680459706e-14\n",
      "Training Circuit at Epoch 497/500; Loss: 6.88338275267597e-14\n",
      "Training Circuit at Epoch 498/500; Loss: 6.894484982922222e-14\n",
      "Training Circuit at Epoch 499/500; Loss: 6.694644838489694e-14\n",
      "Training Circuit at Epoch 500/500; Loss: 6.417089082333405e-14\n"
     ]
    }
   ],
   "source": [
    "final_params, loss_list = circuitModelTuning(\n",
    "        initial_params=init_params,\n",
    "        model=model,\n",
    "        num_epochs=500,\n",
    "        k=intended_k,\n",
    "        op_pool=pool,\n",
    "        opt_callable=qml.AdamOptimizer,\n",
    "        lr=0.01,\n",
    "        grad_noise_factor=0,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa2cc1-9078-477d-8c0c-83f712eb8036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:QuantumResearchPennylane019]",
   "language": "python",
   "name": "conda-env-QuantumResearchPennylane019-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
